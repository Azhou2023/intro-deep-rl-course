{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKTBPBJy-MIp"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "In Part 2 of HW2, we will be implementing neural Q-learning, a deep learning approach to the Q-learning algorithm.\n",
        "\n",
        "**Deep Q-Network (DQN)** is a reinforcement learning algorithm that combines Q-learning with deep neural networks, enabling it to learn optimal policies in complex high-dimensional environments. DQNs employ two neural networks:\n",
        "\n",
        "- The Q-network (main network): Trained frequently during the learning process to approximate the action-value function.\n",
        "- The target network: Used to compute target Q-values. Provides stable target Q-values for the Q-network updates. Periodically copied from the Q-network.\n",
        "\n",
        "During training, the Q-network is updated by minimizing the difference between its predicted Q-values and the target Q-values (which are computed by the target network). This separation reduces instability and divergence, which are common challenges in reinforcement learning with function approximation.\n",
        "\n",
        "The **DQN agent** interacts with the environment, collecting experiences in the form of transitions (s,a,r,sâ€²) and storing them in the *replay buffer*. During training, mini-batches of experiences are sampled and used to train the Q-network.\n",
        "\n",
        "In Part 2, you will implement **DQN** and **DQN agent** which effectively operate on the TextWorld environment. This assignment is divided into the following steps:\n",
        "\n",
        "- Step 1: Implement `DQN`, a neural network used for approximating the Q-function. In this assignment, you will work with a RNN-based text encoder to obtain state representations.\n",
        "- Step 2: Implement `DQNAgent`, an agent containing `DQN`, interacts with environment, saves experiences to the replay buffer, and trains the Q-network.\n",
        "- Step 3: Implement the `run_policy` function. Similar to Part 1. Update the code to work with `DQNAgent`\n",
        "\n",
        "After completing steps 1 through 3, you will test your DQN agent on the same environment and testing suite as in Part 1.\n",
        "\n",
        "**Notes:**\n",
        "- We encourage you to finish Part 1 first before starting Part 2.\n",
        "- All the test configurations of the environment are the same as in Part 1.\n",
        "- Training and testing with a neural network require computations, which may require purchasing API credits. Here are some tips to minimize costs:  \n",
        "    - Implementation and initial testing can be done on CPUs. You can use your local machine or free Colab credits.\n",
        "    - For parameter tuning, you may need more computational power, especially GPUs. Instead of an exhaustive search, try making educated guesses to optimize your parameters efficiently.\n",
        "    - [lightning.ai](https://lightning.ai) also offers free GPU credits.  \n",
        "- ***DO NOT REMOVE ANY COMMENTS THAT HAVE `# EXPORT` IN THEM. THE GRADING SCRIPT USES THESE COMMENTS TO EVALUATE YOUR FUNCTIONS. WE WILL NOT AUDIT SUBMISSIONS TO ADD THESE. IF THE AUTOGRADER FAILS TO RUN DUE TO YOUR MODIFICATION OF THESE COMMENTS, YOU WILL NOT RECEIVE CREDIT.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMJadvTO-O7z"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdVL2D-B-qYC"
      },
      "source": [
        "Install the `TextWorld-Express` engine, `graphviz` and `pydot` for visualization, and `torch` for neural network implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_jkFnjg-C7N",
        "outputId": "da326fa5-1361-4b7c-a0f3-ea7affcba480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from gymnasium) (1.24.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from gymnasium) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: zipp>=3.20 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.20.2)\n",
            "Requirement already satisfied: textworld-express in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (1.0.5)\n",
            "Requirement already satisfied: py4j in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from textworld-express) (0.10.9.9)\n",
            "Requirement already satisfied: orjson in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from textworld-express) (3.10.7)\n",
            "Requirement already satisfied: prompt-toolkit in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from textworld-express) (3.0.48)\n",
            "Requirement already satisfied: wcwidth in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from prompt-toolkit->textworld-express) (0.2.13)\n",
            "Requirement already satisfied: graphviz in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (0.20.3)\n",
            "Requirement already satisfied: pydot in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from pydot) (3.0.9)\n",
            "Requirement already satisfied: torch in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (1.12.1)\n",
            "Requirement already satisfied: typing_extensions in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: transformers in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install textworld-express\n",
        "!pip install graphviz\n",
        "!pip install pydot\n",
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0GaE8xE-T6A"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_ScAIKmf-Vmm"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "# imports for environment\n",
        "from textworld_express import TextWorldExpressEnv\n",
        "import gymnasium\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# imports for DQN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U9ElZek-y5I"
      },
      "source": [
        "# Load a Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg_yOwlT_ByQ"
      },
      "source": [
        "Set the random seed for repeatablity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "cIGNj42d-93N"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "SEED = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8_CqmGx_GOo"
      },
      "source": [
        "Initialize the game environment. `ENV` is a global that encapulates the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "CRwKCeqK_JOy"
      },
      "outputs": [],
      "source": [
        "ENV = TextWorldExpressEnv(envStepLimit=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJDssBp_Kd_"
      },
      "source": [
        "Set the game generator to generate a particular game (coin game or map reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "piAle474_SPG"
      },
      "outputs": [],
      "source": [
        "GAME_TYPE = \"coin\"\n",
        "GAME_PARAMS = \"numLocations=5,includeDoors=1,numDistractorItems=0\"\n",
        "ENV.load(gameName=GAME_TYPE, gameParams=GAME_PARAMS)\n",
        "obs, infos = ENV.reset(seed=SEED, gameFold=\"train\", generateGoldPath=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utility Functions\n",
        "\n",
        "This section defines utility functions for Part 2. Most of these functions do not require modification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SkcfE1CA_a4"
      },
      "source": [
        "Environment Interaction Functions (see the description in Part 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "e5zs1sspRvDy"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def reset_mdp(env):\n",
        "  obs, infos = env.reset(seed=SEED, gameFold=\"train\", generateGoldPath=True)\n",
        "  valids = infos['validActions']\n",
        "  valids.remove('inventory')\n",
        "  valids.remove('look around')\n",
        "  inv = infos['inventory']\n",
        "  modified_obs = obs_with_inventory(infos['look'], inv)\n",
        "  # return make_state_mdp(infos['look'], parse_inventory(infos['inventory'])), valids\n",
        "  return {'observation': infos['look'],\n",
        "          'inventory': infos['inventory'],\n",
        "          'valid actions': valids,\n",
        "          'modified_obs': modified_obs}\n",
        "\n",
        "\n",
        "def do_action_mdp(action, env):\n",
        "  obs, reward, done, infos = env.step(action)\n",
        "  #obs_look, reward_look, done_look, infos_look = env.step('look around')\n",
        "  valid_actions = infos['validActions']\n",
        "  valid_actions.remove('inventory')\n",
        "  valid_actions.remove('look around')\n",
        "  # return make_state_mdp(infos['look'], parse_inventory(infos['inventory'])), reward, done, valid_actions\n",
        "  return infos['look'], reward, done, {'observation': infos['look'],\n",
        "                                       'inventory': infos['inventory'],\n",
        "                                       'valid actions': valid_actions}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKVzzXoVldvm"
      },
      "source": [
        "Define `pad_sequences`, which is used in Step 2 to pad text sequences into the same size for batching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "p3sUHa7klfta"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def pad_sequences(sequences, maxlen=None, dtype='int32', value=0.):\n",
        "    '''\n",
        "    Partially borrowed from Keras\n",
        "    # Arguments\n",
        "        sequences: list of lists where each element is a sequence\n",
        "        maxlen: int, maximum length\n",
        "        dtype: type to cast the resulting sequence.\n",
        "        value: float, value to pad the sequences to the desired value.\n",
        "    # Returns\n",
        "        x: numpy array with dimensions (number_of_sequences, maxlen)\n",
        "    '''\n",
        "    lengths = [len(s) for s in sequences]\n",
        "    nb_samples = len(sequences)\n",
        "    if maxlen is None:\n",
        "        maxlen = np.max(lengths)\n",
        "    # take the sample shape from the first non empty sequence\n",
        "    # checking for consistency in the main loop below.\n",
        "    sample_shape = tuple()\n",
        "    for s in sequences:\n",
        "        if len(s) > 0:\n",
        "            sample_shape = np.asarray(s).shape[1:]\n",
        "            break\n",
        "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
        "    for idx, s in enumerate(sequences):\n",
        "        if len(s) == 0:\n",
        "            continue  # empty list was found\n",
        "        # pre truncating\n",
        "        trunc = s[-maxlen:]\n",
        "        # check `trunc` has expected shape\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "        if trunc.shape[1:] != sample_shape:\n",
        "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
        "                             (trunc.shape[1:], idx, sample_shape))\n",
        "        # post padding\n",
        "        x[idx, :len(trunc)] = trunc\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkVHzerAk4Y3"
      },
      "source": [
        "The action set used in Part 2. This mapping table is used when we initialize DQN to set the number of final outputs (action space) and to map action strings to numerical IDs and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "3LZ2EKgWkn_X"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "action_set = {\n",
        "  'look around': 0,\n",
        "  'close door to west': 1,\n",
        "  'close door to east': 2,\n",
        "  'close door to south': 3,\n",
        "  'close door to north': 4,\n",
        "  'move west': 5,\n",
        "  'move east': 6,\n",
        "  'move south': 7,\n",
        "  'move north': 8,\n",
        "  'open door to west': 9,\n",
        "  'open door to east': 10,\n",
        "  'open door to south': 11,\n",
        "  'open door to north': 12,\n",
        "  'inventory': 13,\n",
        "  'take coin': 14,\n",
        "  'read map': 15,\n",
        "  'put map in box': 16,\n",
        "  'task': 17,\n",
        "  'take map': 18,\n",
        "  'put coin in box': 19\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn5CeI-VtYiG"
      },
      "source": [
        "In Part 2, we need to encode textual states, which is more computationally expensive than using a simple Q-table. To improve efficiency, we use some tricks to reduce the length of state representations. We recommend using this `obs_with_inventory` function for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "D1ynrEpntZEZ"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def obs_with_inventory(obs, inv):\n",
        "  # some tricks to reduce the length of state\n",
        "  if 'Your inventory is currently empty' in inv:\n",
        "    inv = 'Inventory: empty'\n",
        "\n",
        "  if '(maximum capacity is 2 items)' in inv:\n",
        "    inv = inv.replace(\"(maximum capacity is 2 items)\", \"\")\n",
        "\n",
        "  return obs + '\\n' + inv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJzznPc_wswe"
      },
      "source": [
        "# Important Notes for this Assignment\n",
        "\n",
        "\n",
        "*   A successful episode from the MDP will give a reward of 1.0\n",
        "*   A partially successful episode from an MDP environment will give a reward of 0.5\n",
        "*   If you increase NUM_EPISODES too high, it will take too long in the autograder.\n",
        "*   We will be checking for hard coded values / outputs, so please don't take any shortcuts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sGpjl4N4YP9"
      },
      "source": [
        "# Step 1. Implement `DQN`\n",
        "\n",
        "In this step, we will define how the neural network will encode observations and calculate Q-values to approximate the Q-function.\n",
        "We implement the `DQN` class that estimates the expected Q-values for each possible action in a given state.\n",
        "Since neural networks in the DQN takes inputs in the form of tensor, we need to encode a state to obtain state representations. We adopt a simple RNN-based state network following the paper [Interactive Fiction Games: A Colossal Adventure](https://arxiv.org/pdf/1909.05398) to encode textual states from the Textworld-Express.\n",
        "\n",
        "To help you with this task, we have provided the following three classes:\n",
        "- `PackedEncoderRNN`: This class is a recurrent neural network (RNN) for processing sequential data like text. You don't need to modify this class in this assignment.\n",
        "- `StateNetwork`: This class encodes the observations and inventory information from the TextWorld game, creating a compact representation of the game state. While the current implementation uses one RNN to encode the state, you can optionally explore using more RNNs (as suggested in the [paper](https://arxiv.org/pdf/1909.05398)) to encode observations and inventory separately, concatenating them for the final state representations.\n",
        "- `DQN`: This is the core of the deep Q-Network, containing the `StateNetwork`. **Your main task in this step is to complete the `DQN` class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "3ejeYWxRrtiY"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "class PackedEncoderRNN(nn.Module):\n",
        "  \"\"\"\n",
        "    No need to change, but feel free to improve if needed.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(PackedEncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden=None):\n",
        "    embedded = self.embedding(input).permute(1, 0, 2) # T x Batch x EmbDim\n",
        "    if hidden is None:\n",
        "        hidden = self.initHidden(input.size(0))\n",
        "\n",
        "    # Pack the padded batch of sequences\n",
        "    lengths = torch.tensor([torch.nonzero(n)[-1] + 1 for n in input], dtype=torch.long).cpu()\n",
        "    packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, enforce_sorted=False)\n",
        "    output, hidden = self.gru(packed, hidden)\n",
        "\n",
        "    # Unpack the padded sequence\n",
        "    output, _ = nn.utils.rnn.pad_packed_sequence(output)\n",
        "\n",
        "    # Return only the last timestep of output for each sequence\n",
        "    lengths = lengths.to(device)\n",
        "    idx = (lengths-1).view(-1, 1).expand(len(lengths), output.size(2)).unsqueeze(0)\n",
        "    output = output.gather(0, idx).squeeze(0)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self, batch_size):\n",
        "    return torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "\n",
        "class StateNetwork(nn.Module):\n",
        "  \"\"\"\n",
        "    No need to change, but feel free to improve if needed.\n",
        "  \"\"\"\n",
        "  def __init__(self, config):\n",
        "    super(StateNetwork, self).__init__()\n",
        "    self.config = config\n",
        "    self.enc_state = PackedEncoderRNN(config.vocab_size, config.hidden_size)\n",
        "    self.fcx = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.fch = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    batch_size = inputs.shape[0]\n",
        "    x_o, h_o = self.enc_state(inputs, self.enc_state.initHidden(batch_size))\n",
        "\n",
        "    x = F.relu(self.fcx(x_o))\n",
        "    h = F.relu(self.fch(h_o))\n",
        "\n",
        "    return x, h\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(DQN, self).__init__()\n",
        "    self.state_network = StateNetwork(config)\n",
        "    self.act_scorer = nn.Linear(config.hidden_size, config.act_size)\n",
        "\n",
        "  def forward(self, state):\n",
        "    \"\"\"\n",
        "      the output should be (BATCH_SIZE, ACTION_SIZE): the estimated Q-values for each action given a state\n",
        "    \"\"\"\n",
        "    encoding_x, encoding_h = self.state_network(state)\n",
        "    return self.act_scorer(encoding_x)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt3zgQxTX0x0"
      },
      "source": [
        "Test your DQN implementation with a simple input example. This is a sanity check and does not guarantee the correctness of your code. You will test your implementation after Step 2 and Step 3 on the actual environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoRXWfrsXx3p",
        "outputId": "c3beb5f4-471a-4d0d-a438-5f2268b762da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******** Q-values ******** (not trained)\n",
            "look around         : -0.089469\n",
            "close door to west  : 0.109600\n",
            "close door to east  : 0.034183\n",
            "close door to south : 0.075443\n",
            "close door to north : -0.021584\n",
            "move west           : 0.020146\n",
            "move east           : -0.232662\n",
            "move south          : -0.076713\n",
            "move north          : 0.101618\n",
            "open door to west   : 0.034378\n",
            "open door to east   : -0.118141\n",
            "open door to south  : 0.016514\n",
            "open door to north  : 0.151836\n",
            "inventory           : 0.066870\n",
            "take coin           : -0.101632\n",
            "read map            : 0.076312\n",
            "put map in box      : -0.055058\n",
            "task                : 0.067009\n",
            "take map            : 0.085617\n",
            "put coin in box     : -0.001476\n"
          ]
        }
      ],
      "source": [
        "# Test your DQN implementation\n",
        "\n",
        "class DQNConfig:\n",
        "  vocab_size = 50257 # vocab size of the GPT2 tokenizer. Change only if you want to try a different tokenizer.\n",
        "  act_size = len(action_set)\n",
        "  embedding_size = 64\n",
        "  hidden_size = 256\n",
        "\n",
        "config = DQNConfig()\n",
        "dqn = DQN(config).to(device)\n",
        "x = torch.tensor([0, 1, 2, 3, 4, 5]).to(device).unsqueeze(0) # random input token ids\n",
        "print(\"******** Q-values ******** (not trained)\")\n",
        "q_values = dqn(x)\n",
        "for act, actid in action_set.items():\n",
        "  print(f\"{act:20}: {q_values[0][actid]:0.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhgPPbfb9ANG"
      },
      "source": [
        "# Step 2: Implement `DQNAgent`\n",
        "\n",
        "In this step, you will implement the `DQNAgent` class, which encapsulates the `DQN` model and the core logic for interacting with the environment, storing experiences, and training the neural network. The `DQNAgent` is responsible for:\n",
        "\n",
        "* Interacting with the environment: Using `reset_mdp()` to initialize an episode and `do_action_mdp()` to take actions and observe the consequences.\n",
        "* Storing experiences: Saving transitions (state, action, reward, next state, done) in a replay buffer for experience replay.\n",
        "* Estimating Q-values: Using the `DQN` model to predict the expected Q-values for each action in a given state.\n",
        "* Training the neural network: Updating the `DQN` model's parameters based on the experiences stored in the replay buffer.\n",
        "\n",
        "Note that the `train` function will serve as the entry point for the training process. For example, we will use this code to create and train your agent:\n",
        "\n",
        "```\n",
        "agent = DQNAgent(action_set, DQNConfig(), gamma=GAMMA, epsilon=EPSILON)\n",
        "agent.train(ENV, NUM_EPISODES, THRESHOLD)\n",
        "```\n",
        "\n",
        "The `train` function takes the following arguments:\n",
        "\n",
        "* `env`: The TextWorldExpress environment (`ENV`).\n",
        "* `num_episodes`: The total number of episodes to train for.\n",
        "* `threshold`: The maximum number of steps allowed in a single episode.\n",
        "\n",
        "**Design Considerations:**\n",
        "\n",
        "Apart from the `train` function, you have flexibility in designing the internal structure and methods of the `DQNAgent` class. Here are some recommendations to guide your implementation:\n",
        "\n",
        "* Epsilon Decay: Gradually decrease the exploration rate (epsilon) over time to shift from exploration to exploitation. (use `epsilon_decay` and `epsilon_min`)\n",
        "* Target Network Update: Periodically update the target network with the weights of the main Q-network (e.g., every 1000 steps) to stabilize training. (use `update_freq_target`)\n",
        "* Q-Network Update Frequency: Update the Q-network every few steps (e.g., every 4 steps) rather than after every single step to improve efficiency and stability. (use `update_freq` )\n",
        "\n",
        "Note that your function will interact with the environment through `reset_mdp()` and `do_action_mdp()`. Be sure to reset the environment before running, and terminate the episode if `do_action_mdp()` indicates the episode has terminated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R02kCLNnrvUa"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "import sys\n",
        "\n",
        "\n",
        "class DQNAgent:\n",
        "  def __init__(self,\n",
        "               action_set,\n",
        "               dqn_config,\n",
        "               gamma,\n",
        "               epsilon,\n",
        "               learning_rate=0.0005,\n",
        "               epsilon_decay=0.96,\n",
        "               epsilon_min=0.01,\n",
        "               batch_size=64,\n",
        "               memory_size=100000,\n",
        "               update_freq=4,\n",
        "               update_freq_target=1000):\n",
        "    self.act2id = {a: i for i, a in enumerate(action_set)}\n",
        "    self.id2act = {i: a for i, a in enumerate(action_set)}\n",
        "\n",
        "    self.update_freq = update_freq\n",
        "    self.update_freq_target = update_freq_target\n",
        "    self.max_seq_len = 256  # DO NOT CHANGE `max_seq_len`\n",
        "    self.tokenizer =  AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "    self.gamma = gamma\n",
        "    self.epsilon = epsilon\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.epsilon_min = epsilon_min\n",
        "    self.batch_size = batch_size\n",
        "    self.replay_buffer = deque(maxlen=memory_size)\n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.model = DQN(dqn_config).to(self.device)\n",
        "    self.target_model = DQN(dqn_config).to(self.device)\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "  def tokenize_and_pad_states(self, states):\n",
        "    \"\"\"\n",
        "    Tokenizes and pads a list of textual states.\n",
        "    Uses the pre-trained tokenizer to convert textual descriptions of\n",
        "    the environment into numerical representations (tokens) and then pads\n",
        "    the sequences to a uniform length.\n",
        "\n",
        "    Args:\n",
        "        states: A list of string representations of the environment state.\n",
        "\n",
        "    Returns:\n",
        "        A padded NumPy array of tokenized states.\n",
        "    \"\"\"\n",
        "    input_ids = self.tokenizer(states)['input_ids']\n",
        "    return pad_sequences(input_ids, maxlen=self.max_seq_len)\n",
        "\n",
        "  def get_next_action(self, obs):\n",
        "    state_input = torch.tensor([self.tokenizer(obs)['input_ids']])\n",
        "    state_input = state_input.to(self.device)\n",
        "    Q_output = list(self.model(state_input)[0])\n",
        "    next_action_index = Q_output.index(max(Q_output))\n",
        "    next_action = self.id2act[next_action_index]\n",
        "    return next_action\n",
        "    \n",
        "\n",
        "  def train(self, env, num_episodes, threshold):\n",
        "    \"\"\"Trains the DQN agent in the given environment.\n",
        "\n",
        "    Args:\n",
        "      env: The environment to train the agent in.\n",
        "      num_episodes: The number of episodes to train for.\n",
        "      threshold: The maximum number of steps to take in each episode.\n",
        "\n",
        "    Returns:\n",
        "      - A list of rewards obtained in each episode.\n",
        "    \"\"\"\n",
        "    loss_function = torch.nn.MSELoss()\n",
        "    all_rewards = []  # Store rewards for each episode\n",
        "    total_step = 0\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "      eps_reward = 0\n",
        "      reset_result = reset_mdp(env)\n",
        "      obs = reset_result[\"modified_obs\"]\n",
        "      actions = reset_result[\"valid actions\"]\n",
        "      actions_list = []\n",
        "      \n",
        "      for step in range(threshold):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "          next_action = random.choice(actions)\n",
        "        else:\n",
        "           state_input = torch.tensor([self.tokenizer(obs)['input_ids']])\n",
        "           state_input = state_input.to(self.device)\n",
        "           Q_star_output = list(self.model(state_input)[0])\n",
        "           next_action_index = Q_star_output.index(max(Q_star_output))\n",
        "           next_action = self.id2act[next_action_index]\n",
        "        actions_list.append(next_action)\n",
        "        new_obs, reward, done, info = do_action_mdp(next_action, env)\n",
        "        eps_reward+=reward\n",
        "        new_obs = obs_with_inventory(info['observation'], info['inventory'])\n",
        "        actions = info['valid actions']\n",
        "        self.replay_buffer.append((obs, next_action, reward, new_obs, done))\n",
        "        obs = new_obs\n",
        "        \n",
        "        if total_step % self.update_freq == 0:\n",
        "          sample = random.sample(self.replay_buffer, min(self.batch_size, len(self.replay_buffer)))\n",
        "            \n",
        "          x = torch.tensor(self.tokenize_and_pad_states([entry[0] for entry in sample]))\n",
        "          y = []\n",
        "          action_set = []\n",
        "          for entry in sample:\n",
        "            (entry_obs, entry_next_action, entry_reward, entry_new_obs, entry_done) = entry\n",
        "            if entry_done:\n",
        "              y.append(torch.tensor(entry_reward))\n",
        "            else:\n",
        "              state_input = torch.tensor([self.tokenizer(entry_new_obs)['input_ids']])\n",
        "              state_input = state_input.to(self.device)\n",
        "              Q_output = list(self.target_model(state_input)[0])\n",
        "              y.append(entry_reward + self.gamma*max(Q_output))\n",
        "            action_set.append([self.act2id[entry_next_action]])\n",
        "            \n",
        "          x = x.to(self.device)\n",
        "          y = torch.tensor(y).to(self.device)\n",
        "          action_set = torch.tensor(action_set).to(self.device)\n",
        "          y_hat = self.model(x).gather(dim=1, index=action_set)\n",
        "          y_hat = torch.squeeze(y_hat, dim=1)\n",
        "          loss = loss_function(y_hat, y)\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "        \n",
        "        if total_step % self.update_freq_target == 0:\n",
        "          self.target_model.load_state_dict(self.model.state_dict())\n",
        "      \n",
        "        total_step+=1\n",
        "\n",
        "        if done:\n",
        "          break\n",
        "      \n",
        "      print(f\"Episode {episode}, Reward: {eps_reward}, Actions: {actions_list}\")\n",
        "      all_rewards.append(eps_reward)\n",
        "      if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon = self.epsilon * self.epsilon_decay\n",
        "      \n",
        "    return all_rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js7x9FBAr_0e"
      },
      "source": [
        "Similar to Part 1, you might need to adjust the hyperparameters NUM_EPISODES, THRESHOLD, GAMMA, and EPSILON from their default values. These variables are just for the simple test below. The autograder will use the variables you set in `set_parameters` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ade0f6ba1195472fb29f9d4141832cde",
            "f2274c8560d340a1ae38e85f25817c90",
            "01d2bdd36f814e3fb134a3e9448c85ad",
            "8a9983fac2884ddb9507bfa3065cf12c",
            "dd4fbf4066374253ad16143f96a1b1f6",
            "7bd0c526ec5548ef94c53abdedd8fa95",
            "f78d1ce3a6da4c71a515616f4e448b6a",
            "9176817e2ea84b62979d94147e480530",
            "ef3c33a2a74246999f326a8331208ec8",
            "0e06cc9e741f4d3a817ac368d30b19ff",
            "f943b84dce384188ac572eab0a24967f",
            "c1e26d30e6fe4b3f8eacce4b2e499363",
            "8c6ff33b38d94cb48a79d37671741eca",
            "63e00825f6e34fbba86863fd162bf93a",
            "9967e32e6143496f8893e4a8941a2043",
            "d9da8f9cd4ba4eab91778d86a309baa6",
            "3d4cd11d435f47c09ee3b560fc53044f",
            "6cb62602bbff41c9a0a9a0e2ac7fde3d",
            "acb90a41322e4018a19e00cc2e97f236",
            "c364fb971bb148b89489b1dd4858e6a9",
            "3acbd604c6b3487eae42ffb73da068e9",
            "490f64b6f88540c69b52187946a6fc93",
            "d5ba1c8986ff4ef593201abe949df2d2",
            "ba9e8fc74a8f46ce87b1512c1e7c1546",
            "14bca33ada594a618759ee84c1ff3494",
            "70c03d55ad6e42b2ad28bd4e94d6c864",
            "42a76986c2114f0285f1d113cfaef9e8",
            "9b050daab9124a86be8855f82b651a31",
            "7798dbd0a7404904a11b0199ce3b8ed0",
            "100bb8dbe1a441e9adf1e81013b7ed5c",
            "d23744705b6c4a4986ae9a0051ffa767",
            "bf879b0dcb684ba68cf666aee89c9ccb",
            "0eb6a7c0ba214a8ea69091c6b561c5f2",
            "2a72ce34d14e49e9942b611381134e24",
            "47c8e12c443c4a6a947b4b7e8bccb8a6",
            "8d73812e12354b6fb8d9b9ad928c8d86",
            "28813c105e7946b9b4fe9ae500b39023",
            "a95d2510d9ad4df683fbfb22e5b4dde0",
            "a1c710352c2740abb073ced77e824987",
            "99bf57b7e6714f9ba8ac3e67b0852a22",
            "1280b721212e463398dad9a9269ec2e4",
            "b6837c8777f244b8a5a48aa23960d0ed",
            "d20276010dd343df9a5498795131f57e",
            "125b82cd74184e2f9399afafd391c511",
            "eba7a4d7aa8e425b9cbe8e31c459483e",
            "bfe3ae9de1674d0baa92919aa8ff476c",
            "fc4f9c38b9a1488c9aa2d17829723785",
            "b01ce2a8b721466590e8aff1a3bfd10d",
            "4a5f68ab463643a085166a75405b5d44",
            "45e81bb07cf64455a91aaebb9b592cb8",
            "f14b30395edd4bf0802d9c9a6fb7baad",
            "29a68ad51db7437cb1e708f82597ba4b",
            "e1d5a481148b40e59c1aeb859e6bf5ce",
            "fe936253ad4c4b049fe050ae6f7e62ef",
            "0901f8bc04c747a0841b5108f0a01da0"
          ]
        },
        "id": "fvCsvElH0TSD",
        "outputId": "81343d88-dc74-4331-c9ed-50ba99952e81"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "NUM_EPISODES = 150\n",
        "THRESHOLD = 100\n",
        "GAMMA = 0.75\n",
        "EPSILON = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a DQNAgent and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Episode 0, Reward: 1.0, Actions: ['open door to south', 'open door to south', 'move south', 'close door to east', 'close door to east', 'close door to north', 'move north', 'move north', 'close door to east', 'close door to north', 'close door to east', 'close door to east', 'open door to north', 'close door to east', 'close door to north', 'open door to north', 'open door to east', 'move north', 'close door to west', 'open door to west', 'close door to south', 'close door to south', 'close door to west', 'open door to west', 'move west', 'close door to east', 'close door to east', 'move east', 'open door to east', 'close door to east', 'move east', 'open door to east', 'open door to east', 'open door to east', 'close door to east', 'open door to east', 'close door to east', 'close door to east', 'close door to east', 'open door to east', 'open door to east', 'move east', 'close door to south', 'open door to south', 'move south', 'move north', 'open door to south', 'move south', 'close door to east', 'close door to east', 'move east', 'close door to east', 'move east', 'open door to east', 'move east', 'move west', 'open door to east', 'open door to east', 'move east', 'take coin']\n",
            "Episode 1, Reward: 1.0, Actions: ['move south', 'move south', 'open door to south', 'close door to west', 'open door to south', 'read map', 'open door to south', 'close door to south', 'move south', 'read map', 'open door to south', 'move south', 'open door to north', 'open door to north', 'open door to east', 'open door to east', 'open door to east', 'open door to east', 'open door to east', 'open door to north', 'close door to east', 'close door to north', 'close door to north', 'move east', 'open door to north', 'close door to east', 'open door to east', 'close door to north', 'close door to east', 'move north', 'close door to north', 'move north', 'close door to east', 'close door to north', 'open door to east', 'move north', 'open door to north', 'move east', 'move west', 'move east', 'take coin']\n",
            "Episode 2, Reward: 1.0, Actions: ['close door to south', 'move south', 'close door to west', 'open door to south', 'move west', 'open door to south', 'close door to south', 'move west', 'close door to west', 'open door to west', 'close door to west', 'open door to west', 'move south', 'close door to west', 'close door to south', 'move west', 'open door to south', 'move south', 'move north', 'close door to west', 'open door to west', 'close door to south', 'open door to west', 'close door to south', 'move west', 'open door to east', 'open door to east', 'move east', 'open door to west', 'close door to west', 'open door to west', 'open door to west', 'move west', 'move east', 'close door to south', 'close door to south', 'close door to west', 'close door to west', 'move west', 'close door to south', 'close door to west', 'open door to west', 'move south', 'open door to west', 'move south', 'open door to south', 'close door to west', 'close door to west', 'move west', 'move south', 'open door to east', 'open door to east', 'close door to east', 'close door to north', 'open door to east', 'close door to north', 'move north', 'move north', 'close door to east', 'move east', 'move north', 'move east', 'close door to east', 'open door to north', 'move east', 'open door to east', 'move east', 'take coin']\n",
            "Episode 3, Reward: 1.0, Actions: ['close door to south', 'close door to west', 'close door to west', 'close door to west', 'move west', 'close door to south', 'open door to south', 'close door to south', 'close door to south', 'move west', 'move south', 'open door to west', 'open door to south', 'move west', 'move east', 'open door to south', 'move west', 'close door to east', 'close door to east', 'open door to east', 'move east', 'move west', 'open door to east', 'move east', 'open door to west', 'open door to west', 'move south', 'open door to north', 'open door to north', 'close door to north', 'take coin', 'close door to east', 'close door to north', 'move east', 'move east', 'move east', 'open door to east', 'move east', 'open door to west', 'take coin']\n",
            "Episode 4, Reward: 1.0, Actions: ['move west', 'move south', 'close door to west', 'move south', 'open door to south', 'close door to west', 'open door to south', 'move south', 'move north', 'open door to south', 'open door to west', 'move south', 'open door to east', 'move north', 'open door to west', 'open door to south', 'open door to south', 'open door to west', 'move south', 'move east', 'open door to north', 'move west', 'open door to east', 'move east', 'take coin']\n",
            "Episode 5, Reward: 1.0, Actions: ['move south', 'open door to west', 'move west', 'open door to east', 'move east', 'open door to west', 'open door to south', 'open door to west', 'close door to west', 'open door to west', 'open door to west', 'open door to west', 'move south', 'close door to north', 'move east', 'move north', 'open door to north', 'take coin', 'take coin', 'open door to north', 'close door to north', 'move east', 'move east', 'move east', 'close door to north', 'open door to east', 'take coin', 'close door to north', 'move north', 'close door to east', 'move north', 'close door to north', 'move east', 'close door to east', 'close door to north', 'open door to east', 'move east', 'take coin']\n",
            "Episode 6, Reward: 1.0, Actions: ['close door to south', 'take coin', 'take coin', 'close door to south', 'close door to south', 'open door to south', 'take coin', 'open door to south', 'open door to south', 'take coin', 'close door to south', 'move west', 'take coin', 'open door to west', 'open door to south', 'open door to west', 'move west', 'move east', 'move west', 'open door to east', 'take coin', 'move east', 'move west', 'open door to east', 'open door to east', 'open door to east', 'close door to east', 'move east', 'move east', 'take coin', 'move east', 'open door to east', 'move east', 'move west', 'close door to east', 'close door to east', 'take coin', 'close door to east', 'close door to east', 'close door to east', 'open door to east', 'open door to east', 'close door to east', 'open door to east', 'take coin', 'close door to east', 'close door to east', 'move east', 'close door to east', 'open door to east', 'close door to east', 'open door to east', 'move east', 'move south', 'open door to east', 'move east', 'move west', 'close door to east', 'close door to north', 'close door to north', 'open door to east', 'close door to north', 'move east', 'move north', 'take coin']\n",
            "Episode 7, Reward: 1.0, Actions: ['close door to west', 'move south', 'open door to west', 'open door to south', 'close door to west', 'move west', 'close door to south', 'take coin', 'move west', 'take coin', 'move west', 'open door to south', 'open door to west', 'close door to south', 'open door to south', 'close door to south', 'close door to west', 'move west', 'open door to south', 'close door to west', 'move south', 'open door to north', 'close door to north', 'open door to north', 'move east', 'close door to north', 'move north', 'close door to north', 'take coin', 'open door to north', 'close door to east', 'open door to north', 'move north', 'open door to west', 'open door to south', 'open door to west', 'open door to west', 'open door to south', 'move west', 'take coin', 'move east', 'open door to west', 'take coin', 'move west', 'take coin', 'take coin', 'take coin', 'open door to east', 'open door to east', 'take coin', 'move east', 'close door to south', 'open door to west', 'open door to south', 'close door to west', 'move south', 'move east', 'open door to north', 'close door to north', 'open door to east', 'take coin', 'open door to north', 'close door to north', 'move east', 'take coin']\n",
            "Episode 8, Reward: 0.0, Actions: ['open door to west', 'close door to south', 'open door to west', 'move west', 'close door to east', 'close door to east', 'take coin', 'open door to east', 'move east', 'open door to south', 'close door to west', 'move south', 'move east', 'close door to north', 'close door to east', 'take coin', 'take coin', 'close door to north', 'move north', 'open door to north', 'close door to north', 'move east', 'close door to north', 'take coin', 'move east', 'move east', 'close door to north', 'move east', 'close door to east', 'open door to north', 'open door to north', 'take coin', 'close door to east', 'close door to north', 'open door to north', 'move north', 'open door to south', 'move south', 'open door to north', 'move north', 'open door to south', 'close door to south', 'open door to south', 'open door to west', 'open door to south', 'take coin', 'move west', 'open door to east', 'close door to east', 'open door to east', 'open door to east', 'close door to east', 'open door to east', 'close door to east', 'open door to east', 'close door to east', 'move west', 'move east', 'open door to east', 'move east', 'close door to west', 'open door to south', 'open door to south', 'move south', 'move west', 'open door to east', 'take coin', 'take coin', 'close door to east', 'open door to east', 'close door to north', 'close door to north', 'open door to north', 'move north', 'open door to west', 'move south', 'close door to north', 'open door to east', 'close door to north', 'read map', 'close door to north', 'move north', 'close door to north', 'close door to north', 'move north', 'open door to east', 'close door to east', 'close door to east', 'open door to north', 'close door to east', 'open door to north', 'read map', 'move east', 'close door to north', 'read map', 'open door to east', 'read map', 'open door to north', 'close door to north', 'move north']\n",
            "Episode 9, Reward: 1.0, Actions: ['close door to south', 'move south', 'read map', 'close door to south', 'open door to west', 'move west', 'move east', 'open door to south', 'close door to west', 'move south', 'open door to east', 'open door to east', 'close door to east', 'move east', 'read map', 'open door to north', 'move north', 'open door to west', 'open door to west', 'move west', 'move east', 'close door to south', 'open door to south', 'move south', 'move east', 'move north', 'open door to west', 'close door to west', 'open door to west', 'move west', 'move east', 'open door to south', 'close door to west', 'close door to south', 'move west', 'take coin', 'close door to west', 'move west', 'close door to west', 'move west', 'move west', 'close door to west', 'take coin', 'close door to south', 'open door to south', 'take coin', 'open door to west', 'move south', 'open door to east', 'move east', 'close door to west', 'move west', 'take coin']\n",
            "Episode 10, Reward: 0.0, Actions: ['close door to west', 'move south', 'move west', 'take coin', 'close door to west', 'close door to south', 'take coin', 'open door to west', 'take coin', 'close door to west', 'take coin', 'take coin', 'move south', 'move west', 'open door to east', 'open door to west', 'take coin', 'move south', 'open door to west', 'take coin', 'take coin', 'move west', 'move east', 'take coin', 'close door to west', 'close door to south', 'open door to west', 'open door to west', 'open door to west', 'take coin', 'open door to south', 'take coin', 'open door to west', 'open door to south', 'close door to south', 'take coin', 'move south', 'open door to west', 'close door to south', 'take coin', 'take coin', 'move west', 'open door to east', 'open door to east', 'move east', 'open door to south', 'move south', 'open door to east', 'close door to east', 'move north', 'take coin', 'open door to south', 'open door to west', 'take coin', 'close door to west', 'open door to south', 'take coin', 'open door to west', 'move west', 'close door to east', 'take coin', 'close door to east', 'move east', 'close door to east', 'move east', 'open door to west', 'move east', 'move east', 'open door to east', 'close door to east', 'close door to east', 'take coin', 'move east', 'take coin', 'close door to east', 'open door to east', 'close door to east', 'move east', 'open door to east', 'move east', 'take coin', 'open door to west', 'take coin', 'move west', 'open door to east', 'close door to east', 'open door to east', 'close door to east', 'open door to east', 'open door to east', 'open door to east', 'move east', 'open door to west', 'move south', 'open door to east', 'open door to west', 'move north', 'close door to west', 'close door to east', 'open door to west']\n",
            "Episode 11, Reward: 1.0, Actions: ['move west', 'close door to west', 'open door to west', 'move south', 'close door to east', 'open door to south', 'move south', 'take coin', 'open door to east', 'move north', 'open door to west', 'close door to west', 'take coin', 'close door to west', 'move west', 'take coin', 'close door to west', 'move west', 'move west', 'open door to south', 'move south', 'close door to south', 'move east', 'open door to north', 'move west', 'close door to south', 'close door to east', 'move east', 'take coin', 'open door to east', 'open door to east', 'open door to west', 'open door to west', 'open door to north', 'close door to east', 'move east', 'close door to north', 'take coin', 'move east', 'open door to east', 'move east', 'take coin']\n",
            "Episode 12, Reward: 1.0, Actions: ['open door to west', 'open door to west', 'close door to south', 'open door to south', 'close door to west', 'open door to south', 'move west', 'open door to west', 'move south', 'move east', 'move north', 'close door to south', 'open door to west', 'close door to south', 'close door to east', 'move west', 'close door to east', 'close door to east', 'open door to east', 'close door to east', 'close door to east', 'open door to east', 'move east', 'move south', 'open door to south', 'open door to south', 'open door to west', 'close door to west', 'move south', 'open door to north', 'close door to east', 'close door to north', 'open door to north', 'take coin', 'close door to east', 'open door to north', 'close door to north', 'close door to north', 'open door to north', 'close door to east', 'open door to north', 'open door to north', 'open door to east', 'open door to west', 'open door to north', 'close door to north', 'move north', 'move east', 'move north', 'move north', 'move west', 'move north', 'open door to west', 'open door to west', 'open door to west', 'close door to east', 'open door to east', 'close door to north', 'take coin', 'close door to east', 'move east', 'open door to north', 'open door to east', 'open door to east', 'close door to north', 'close door to east', 'move north', 'take coin', 'close door to east', 'open door to east', 'close door to east', 'close door to north', 'move east', 'open door to east', 'close door to north', 'read map', 'close door to east', 'take coin', 'take coin', 'open door to east', 'move north', 'take coin', 'move east', 'move north', 'take coin']\n",
            "Episode 13, Reward: 1.0, Actions: ['take coin', 'move west', 'open door to south', 'take coin', 'move west', 'close door to west', 'open door to south', 'move south', 'take coin', 'open door to east', 'close door to north', 'open door to north', 'move north', 'move south', 'close door to east', 'open door to east', 'open door to east', 'move north', 'move west', 'close door to south', 'close door to south', 'open door to west', 'open door to west', 'open door to west', 'open door to west', 'open door to west', 'close door to south', 'move south', 'move west', 'close door to east', 'move east', 'move east', 'close door to east', 'close door to east', 'open door to south', 'close door to east', 'move east', 'open door to east', 'move east', 'move west', 'move east', 'move west', 'close door to east', 'open door to east', 'move east', 'close door to west', 'move south', 'open door to west', 'move south', 'open door to west', 'close door to south', 'open door to west', 'close door to west', 'close door to south', 'open door to west', 'close door to east', 'close door to east', 'open door to south', 'move south', 'move east', 'take coin']\n",
            "Episode 14, Reward: 1.0, Actions: ['open door to west', 'close door to east', 'close door to west', 'open door to west', 'open door to west', 'close door to west', 'move south', 'open door to west', 'move west', 'open door to west', 'open door to east', 'open door to east', 'close door to east', 'close door to east', 'open door to east', 'close door to east', 'close door to east', 'move east', 'move south', 'close door to east', 'move east', 'move east', 'move east', 'close door to east', 'close door to east', 'take coin', 'take coin', 'open door to east', 'open door to east', 'close door to east', 'move east', 'take coin', 'open door to east', 'take coin', 'close door to east', 'take coin', 'take coin', 'close door to east', 'move east', 'open door to east', 'close door to east', 'close door to east', 'close door to east', 'close door to east', 'move east', 'close door to east', 'open door to east', 'move east', 'open door to south', 'take coin', 'open door to west', 'close door to south', 'close door to south', 'open door to west', 'open door to west', 'move south', 'open door to south', 'open door to west', 'move south', 'move north', 'open door to south', 'open door to south', 'move south', 'open door to north', 'close door to north', 'close door to north', 'close door to east', 'move north', 'move east', 'open door to east', 'close door to north', 'close door to east', 'open door to north', 'open door to north', 'move east', 'open door to north', 'open door to east', 'move east', 'open door to north', 'take coin']\n",
            "Episode 15, Reward: 1.0, Actions: ['move east', 'close door to south', 'open door to south', 'move west', 'move south', 'close door to north', 'move north', 'close door to north', 'take coin', 'take coin', 'move east', 'close door to east', 'move north', 'take coin', 'close door to north', 'take coin', 'open door to east', 'move east', 'open door to west', 'take coin']\n",
            "Episode 16, Reward: 1.0, Actions: ['take coin', 'open door to west', 'open door to south', 'take coin', 'move south', 'close door to east', 'take coin', 'move east', 'move east', 'take coin', 'move east', 'open door to north', 'open door to east', 'take coin', 'open door to east', 'move east', 'take coin']\n",
            "Episode 17, Reward: 1.0, Actions: ['open door to west', 'move west', 'open door to south', 'open door to south', 'open door to south', 'close door to east', 'close door to east', 'open door to east', 'move east', 'close door to west', 'close door to west', 'open door to south', 'open door to south', 'move south', 'close door to west', 'move east', 'close door to west', 'close door to west', 'move east', 'move east', 'close door to west', 'move east', 'close door to west', 'move north', 'close door to west', 'open door to north', 'open door to west', 'close door to west', 'move south', 'open door to north', 'open door to east', 'close door to east', 'open door to north', 'move north', 'close door to south', 'open door to west', 'close door to east', 'close door to south', 'move west', 'move west', 'close door to east', 'close door to east', 'close door to east', 'open door to east', 'open door to east', 'move south', 'open door to east', 'close door to east', 'close door to east', 'close door to east', 'move east', 'open door to east', 'move east', 'move south', 'move east', 'open door to south', 'move south', 'close door to east', 'move east', 'move east', 'open door to north', 'move north', 'move east', 'close door to west', 'open door to south', 'move east', 'open door to south', 'move east', 'move east', 'open door to south', 'move east', 'open door to west', 'open door to south', 'move south', 'open door to north', 'open door to east', 'move east', 'open door to north', 'take coin']\n",
            "Episode 18, Reward: 0.0, Actions: ['move east', 'move east', 'open door to south', 'move west', 'move east', 'move east', 'move west', 'move east', 'close door to south', 'move west', 'move east', 'close door to west', 'move west', 'move south', 'open door to west', 'move east', 'move east', 'move east', 'close door to west', 'move west', 'open door to south', 'move south', 'open door to west', 'open door to west', 'close door to north', 'move east', 'open door to north', 'close door to east', 'open door to north', 'move east', 'move north', 'open door to west', 'open door to west', 'move south', 'move east', 'move east', 'move east', 'move north', 'move east', 'open door to west', 'move east', 'move west', 'close door to east', 'move east', 'close door to east', 'move east', 'move east', 'move east', 'open door to east', 'move east', 'close door to west', 'move south', 'close door to east', 'move east', 'open door to east', 'close door to east', 'close door to east', 'move east', 'close door to east', 'move east', 'move east', 'move east', 'move east', 'close door to north', 'open door to north', 'move north', 'move north', 'close door to west', 'move south', 'move north', 'move north', 'move west', 'move north', 'move west', 'move east', 'open door to south', 'close door to south', 'move west', 'open door to south', 'move south', 'move east', 'close door to east', 'open door to north', 'move east', 'move east', 'close door to east', 'open door to west', 'move north', 'open door to west', 'close door to west', 'open door to west', 'move east', 'move east', 'open door to south', 'close door to west', 'open door to south', 'close door to south', 'move south', 'move south', 'move west']\n",
            "Episode 19, Reward: 0.0, Actions: ['move south', 'move south', 'open door to south', 'move south', 'move east', 'open door to west', 'open door to east', 'move north', 'open door to west', 'close door to west', 'open door to west', 'open door to south', 'close door to south', 'close door to west', 'open door to west', 'open door to west', 'close door to south', 'open door to west', 'move west', 'open door to east', 'open door to east', 'close door to east', 'open door to east', 'close door to east', 'close door to east', 'open door to east', 'move east', 'move east', 'open door to south', 'move west', 'open door to east', 'move east', 'close door to south', 'move east', 'move west', 'read map', 'move east', 'open door to west', 'move east', 'move east', 'move east', 'move south', 'close door to west', 'close door to south', 'move west', 'close door to west', 'open door to south', 'close door to south', 'open door to south', 'open door to south', 'move south', 'close door to east', 'open door to north', 'close door to north', 'move east', 'move north', 'close door to east', 'move east', 'move north', 'move east', 'move east', 'move north', 'close door to east', 'close door to north', 'move east', 'move east', 'close door to north', 'close door to north', 'close door to north', 'move north', 'move east', 'close door to north', 'open door to north', 'move east', 'move east', 'open door to north', 'move north', 'move north', 'open door to south', 'open door to south', 'open door to west', 'open door to south', 'move north', 'move west', 'move north', 'open door to east', 'move east', 'move north', 'close door to south', 'open door to south', 'move south', 'move north', 'take coin', 'take coin', 'move south', 'close door to east', 'close door to north', 'close door to south', 'close door to south', 'close door to south']\n",
            "Episode 20, Reward: 1.0, Actions: ['move west', 'close door to south', 'open door to west', 'open door to west', 'close door to west', 'open door to west', 'close door to south', 'close door to south', 'open door to west', 'close door to west', 'close door to south', 'open door to south', 'close door to south', 'open door to west', 'read map', 'open door to south', 'move south', 'close door to south', 'move north', 'open door to south', 'close door to south', 'open door to west', 'read map', 'read map', 'read map', 'close door to west', 'close door to north', 'close door to north', 'close door to west', 'move south', 'move north', 'close door to south', 'open door to west', 'read map', 'open door to west', 'close door to west', 'move north', 'close door to south', 'move south', 'close door to west', 'close door to west', 'close door to west', 'move west', 'open door to south', 'move west', 'take coin', 'move west', 'move west', 'take coin', 'take coin', 'take coin', 'open door to south', 'take coin', 'take coin', 'take coin', 'open door to south', 'take coin', 'close door to west', 'open door to west', 'close door to west', 'open door to south', 'open door to south', 'move west', 'open door to west', 'move south', 'open door to north', 'open door to west', 'open door to west', 'close door to east', 'close door to north', 'close door to east', 'close door to north', 'close door to north', 'open door to west', 'open door to north', 'open door to west', 'move east', 'open door to west', 'close door to north', 'close door to north', 'take coin', 'move north', 'move east', 'close door to east', 'close door to east', 'open door to east', 'open door to east', 'move east', 'take coin']\n",
            "Episode 21, Reward: 1.0, Actions: ['close door to west', 'take coin', 'open door to west', 'take coin', 'open door to south', 'open door to west', 'take coin', 'open door to south', 'take coin', 'open door to south', 'move south', 'close door to east', 'take coin', 'open door to north', 'open door to north', 'open door to east', 'move east', 'open door to north', 'move north', 'move east', 'move east', 'move east', 'close door to south', 'open door to south', 'move south', 'open door to north', 'take coin']\n",
            "Episode 22, Reward: 1.0, Actions: ['move west', 'open door to west', 'move south', 'open door to west', 'open door to west', 'move south', 'move south', 'move west', 'move east', 'move south', 'move south', 'open door to south', 'move south', 'open door to north', 'move south', 'close door to east', 'open door to east', 'move east', 'close door to west', 'close door to north', 'move west', 'move north', 'take coin']\n",
            "Episode 23, Reward: 1.0, Actions: ['move west', 'move south', 'move south', 'open door to west', 'move south', 'open door to west', 'open door to west', 'take coin', 'close door to west', 'move south', 'open door to west', 'open door to south', 'close door to south', 'take coin', 'open door to south', 'open door to west', 'close door to west', 'open door to south', 'take coin', 'close door to west', 'move south', 'move east', 'open door to north', 'close door to north', 'close door to east', 'close door to east', 'close door to north', 'open door to east', 'move east', 'take coin']\n",
            "Episode 24, Reward: 1.0, Actions: ['take coin', 'move south', 'take coin', 'move west', 'move west', 'open door to south', 'open door to south', 'close door to west', 'open door to west', 'close door to west', 'open door to south', 'close door to west', 'close door to west', 'close door to west', 'take coin', 'move south', 'take coin', 'take coin', 'close door to east', 'take coin', 'move east', 'open door to north', 'move north', 'move south', 'close door to north', 'close door to east', 'take coin', 'move east', 'take coin', 'take coin', 'take coin', 'take coin', 'take coin', 'open door to west', 'close door to north', 'open door to west', 'open door to west', 'take coin', 'open door to east', 'move east', 'take coin']\n",
            "Episode 25, Reward: 1.0, Actions: ['move west', 'close door to west', 'move west', 'open door to south', 'open door to west', 'open door to west', 'move south', 'open door to north', 'move east', 'close door to east', 'take coin', 'open door to east', 'move east', 'take coin']\n",
            "Episode 26, Reward: 1.0, Actions: ['close door to west', 'move south', 'open door to west', 'move south', 'close door to south', 'move south', 'move south', 'move south', 'move south', 'move south', 'close door to south', 'close door to west', 'move west', 'move south', 'close door to south', 'open door to south', 'move south', 'move south', 'move north', 'move south', 'move east', 'close door to north', 'move east', 'open door to east', 'move east', 'move north', 'move north', 'close door to north', 'take coin']\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[84], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(action_set, DQNConfig(), gamma\u001b[38;5;241m=\u001b[39mGAMMA, epsilon\u001b[38;5;241m=\u001b[39mEPSILON)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[1;32m----> 3\u001b[0m all_rewards \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mENV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESHOLD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_rewards)\n",
            "Cell \u001b[1;32mIn[82], line 113\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[1;34m(self, env, num_episodes, threshold)\u001b[0m\n\u001b[0;32m    111\u001b[0m   state_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(entry_new_obs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m    112\u001b[0m   state_input \u001b[38;5;241m=\u001b[39m state_input\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 113\u001b[0m   Q_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_input\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    114\u001b[0m   y\u001b[38;5;241m.\u001b[39mappend(entry_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmax\u001b[39m(Q_output))\n\u001b[0;32m    115\u001b[0m action_set\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact2id[entry_next_action]])\n",
            "File \u001b[1;32md:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[80], line 69\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    the output should be (BATCH_SIZE, ACTION_SIZE): the estimated Q-values for each action given a state\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m   encoding_x, encoding_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_scorer(encoding_x)\n",
            "File \u001b[1;32md:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[80], line 51\u001b[0m, in \u001b[0;36mStateNetwork.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m     50\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 51\u001b[0m   x_o, h_o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitHidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m   x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcx(x_o))\n\u001b[0;32m     54\u001b[0m   h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfch(h_o))\n",
            "File \u001b[1;32md:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[80], line 23\u001b[0m, in \u001b[0;36mPackedEncoderRNN.forward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     21\u001b[0m lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([torch\u001b[38;5;241m.\u001b[39mnonzero(n)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     22\u001b[0m packed \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(embedded, lengths, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Unpack the padded sequence\u001b[39;00m\n\u001b[0;32m     26\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpad_packed_sequence(output)\n",
            "File \u001b[1;32md:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\conda\\envs\\mangrove-monitoring\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:953\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    950\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    951\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 953\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    956\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "agent = DQNAgent(action_set, DQNConfig(), gamma=GAMMA, epsilon=EPSILON)\n",
        "print(device)\n",
        "all_rewards = agent.train(ENV, NUM_EPISODES, THRESHOLD)\n",
        "print(all_rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z2k4EkrGaMm"
      },
      "source": [
        "# Step 3. Implement Code to Run a Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j5OrjrTtxWM"
      },
      "source": [
        "In this step, you will implement the `run_policy` function to execute the policy learned by the `DQNAgent`. If you have successfully completed Part 1, adapting your existing implementation to work with the `DQNAgent` should be straightforward. \n",
        "\n",
        "**Important:** Ensure that your agent uses **greedy action selection** during policy execution, meaning it always chooses the action with the highest estimated Q-value from the `DQN`. You may implement helper functions within the `DQNAgent` class to facilitate policy execution.\n",
        "\n",
        "The `run_policy` function takes the following arguments:\n",
        "\n",
        "* `agent`: Your trained `DQNAgent` instance.\n",
        "* `env`: The TextWorldExpress environment (e.g., `ENV`).\n",
        "* `threshold`: The maximum number of steps allowed in an episode before termination.\n",
        "\n",
        "Your function should run a single episode from the initial state and return:\n",
        "- A list of actions taken during the episode (e.g., `[act_1, act_2, ... act_n]`).\n",
        "- The total sum reward of all actions taken as a float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7jJCxMBTGdv9"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def run_policy(agent, env, threshold=50):\n",
        "  actions = [] # Store the entire sequence of actions here\n",
        "  total_reward = 0.0 # Store the total sum reward of all actions executed here\n",
        "  reset_result = reset_mdp(env)\n",
        "  obs = reset_result[\"modified_obs\"]\n",
        "  \n",
        "  for step in range(threshold):\n",
        "      \n",
        "    next_action = agent.get_next_action(obs)\n",
        "    \n",
        "    actions.append(next_action)\n",
        "    obs, reward, done, info = do_action_mdp(next_action, env)\n",
        "    total_reward+=reward\n",
        "    obs = obs_with_inventory(info['observation'], info['inventory'])\n",
        "            \n",
        "    if done:\n",
        "      break\n",
        "  print(f\"Policy actions: {actions}\")\n",
        "  return actions, total_reward\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goBOBYvBYzeR"
      },
      "source": [
        "Test your `run_policy` function. Set the threshold value for episode length during policy execution (test time threshold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpK_2wuMuZ7d"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "TEST_THRESHOLD = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWOGP5aWY59n"
      },
      "source": [
        "Run the policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhrGyDGBGrMP",
        "outputId": "44378508-2378-4232-b593-38f1d584f7b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy actions: ['move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west']\n",
            "plan: ['move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west']\n",
            "Total reward: 0.0\n"
          ]
        }
      ],
      "source": [
        "plan, total_reward = run_policy(agent, ENV, threshold = TEST_THRESHOLD)\n",
        "print(\"plan:\", plan)\n",
        "print(\"Total reward:\", total_reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cBfmUDG1XHk"
      },
      "source": [
        "# New Environments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLeYTiUVY9Tj"
      },
      "source": [
        "The following cells are the same as in Part 1: creating new environemnts: `StochasticTextWorldExpressEnv` and `PunishmentTextWorldExpressEnv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "n-hc6VnL793a"
      },
      "outputs": [],
      "source": [
        "NEVER_PICK_ACTIONS = set(['look around', 'inventory'])\n",
        "ENV_VERBOSE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "GsQWZj0H1WeS"
      },
      "outputs": [],
      "source": [
        "class StochasticTextWorldExpressEnv(TextWorldExpressEnv):\n",
        "\n",
        "  def __init__(self, serverPath=None, envStepLimit=100, stochasticity = 0.0):\n",
        "    # Call the super constructor\n",
        "    super().__init__(serverPath, envStepLimit)\n",
        "    # Store the valid actions and stochasticity\n",
        "    self.valid_actions = []\n",
        "    self.stochasticity = stochasticity\n",
        "\n",
        "  def reset(self, seed=None, gameFold=None, gameName=None, gameParams=None, generateGoldPath=False):\n",
        "    # Call the super method\n",
        "    observation, infos = super().reset(seed, gameFold, gameName, gameParams, generateGoldPath)\n",
        "    # Update the valid actions\n",
        "    self.valid_actions = infos['validActions']\n",
        "    return observation, infos\n",
        "\n",
        "  def step(self, action:str):\n",
        "    # If a random value is less than the stochasticity target, choose a random action\n",
        "    if random.random() < self.stochasticity:\n",
        "      temp_valids = copy.deepcopy(self.valid_actions)\n",
        "      # Remove inventory and look around from valid actions to choose from\n",
        "      temp_valids = list(set(self.valid_actions).difference(NEVER_PICK_ACTIONS))\n",
        "      # Pick a random action from whatever remains\n",
        "      action = random.choice(temp_valids)\n",
        "    # If debugging flag is on, print the action that will be executed\n",
        "    if ENV_VERBOSE:\n",
        "      print(\"[[action]]:\", action)\n",
        "    # Call the super class with either the action passed in or the randomly chosen one\n",
        "    observation, reward, isCompleted, infos = super().step(action)\n",
        "    # Update the valid actions\n",
        "    self.valid_actions = infos['validActions']\n",
        "    return observation, reward, isCompleted, infos\n",
        "\n",
        "class PunishmentTextWorldExpressEnv(TextWorldExpressEnv):\n",
        "\n",
        "  def __init__(self, serverPath=None, envStepLimit=100, punishment = 0.0):\n",
        "    # Call the super constructor\n",
        "    super().__init__(serverPath, envStepLimit)\n",
        "    # Store the punishment\n",
        "    self.punishment = punishment\n",
        "    # Store the previous observation\n",
        "    self.previous_observation = None\n",
        "\n",
        "  def step(self, action:str):\n",
        "    # Call the super method\n",
        "    observation, reward, isCompleted, infos = super().step(action)\n",
        "    # If the current look is the same as the previous look, then we have performed an illegal action\n",
        "    if infos['look'] == self.previous_observation:\n",
        "      reward = self.punishment\n",
        "    # Store the previous observation\n",
        "    self.previous_observation = infos['look']\n",
        "    return observation, reward, isCompleted, infos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKV4lUC1agso"
      },
      "source": [
        "New environments must be registered through the Gymnasium API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "OFWWPDS35bMn"
      },
      "outputs": [],
      "source": [
        "# register new environment\n",
        "gymnasium.register(id='TextWorldExpress-StochasticTextWorldExpressEnv-v0',\n",
        "                   entry_point='__main__:StochasticTextWorldExpressEnv')\n",
        "gymnasium.register(id='TextWorldExpress-PunishmentTextWorldExpressEnv-v0',\n",
        "                   entry_point='__main__:PunishmentTextWorldExpressEnv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywMkXNMwQsgZ"
      },
      "source": [
        "# Testing Suite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR9ZHmgw8UFa"
      },
      "source": [
        "This function will run all environments, all game types, all game parameters, and all seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "OLy0jJ9gRA0L"
      },
      "outputs": [],
      "source": [
        "def run_all(environments, games, seeds):\n",
        "  global ENV, GAME_TYPE, GAME_PARAMS, SEED\n",
        "  # Results will contain a key (env type, game type, game params, seed) and values will be plans and total_rewards\n",
        "  results = {}\n",
        "  test_id = 0\n",
        "  total_reward = 0\n",
        "  # Iterate through all environments given\n",
        "  for env in environments:\n",
        "    # set global environment\n",
        "    ENV = env\n",
        "    # Iterate through all game types, the keys of the games dict\n",
        "    for game_type in games:\n",
        "      # Set the global game type\n",
        "      GAME_TYPE = game_type\n",
        "      # Iterate through all game parameters for the given game type in game dict\n",
        "      for params in games[game_type]:\n",
        "        # set the global game params\n",
        "        GAME_PARAMS = params\n",
        "        # load the environment\n",
        "        ENV.load(gameName=GAME_TYPE, gameParams=GAME_PARAMS)\n",
        "        # Iterate through all seeds\n",
        "        for seed in seeds:\n",
        "          print(f\"TESTING {type(ENV)}, {GAME_TYPE}, {GAME_PARAMS}, {seed}\")\n",
        "          # set the global seed\n",
        "          SEED = seed\n",
        "\n",
        "          # Run the DQNAgent and get the policy\n",
        "          agent = DQNAgent(action_set,\n",
        "                           DQNConfig(),\n",
        "                           gamma=GAMMA,\n",
        "                           epsilon=EPSILON)\n",
        "\n",
        "          agent.train(ENV, NUM_EPISODES, THRESHOLD)\n",
        "\n",
        "          # run the policy to get the plan\n",
        "          plan, reward = run_policy(agent, ENV, threshold = TEST_THRESHOLD)\n",
        "\n",
        "          test_id += 1\n",
        "          total_reward += reward\n",
        "\n",
        "          print(f\"TESTING {test_id}: total_reward {total_reward}/{test_id} \\t (reward: {reward})\")\n",
        "          # Store the plan in the results\n",
        "          results[(type(ENV), GAME_TYPE, GAME_PARAMS, SEED)] = (plan, total_reward)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "jeBUqaKWbBQj"
      },
      "outputs": [],
      "source": [
        "seeds = list(range(3))\n",
        "environments = [TextWorldExpressEnv(envStepLimit=100),\n",
        "                StochasticTextWorldExpressEnv(envStepLimit=100, stochasticity=0.25),\n",
        "                PunishmentTextWorldExpressEnv(envStepLimit=100, punishment=-1.0)]\n",
        "games = {'coin':      ['numLocations=5,includeDoors=1,numDistractorItems=0',\n",
        "                       'numLocations=6,includeDoors=1,numDistractorItems=0',\n",
        "                       'numLocations=7,includeDoors=1,numDistractorItems=0',\n",
        "                       'numLocations=10,includeDoors=1,numDistractorItems=0'],\n",
        "         'mapreader': ['numLocations=5,maxDistanceApart=3,includeDoors=0,maxDistractorItemsPerLocation=0',\n",
        "                       'numLocations=8,maxDistanceApart=4,includeDoors=0,maxDistractorItemsPerLocation=0',\n",
        "                       'numLocations=11,maxDistanceApart=5,includeDoors=0,maxDistractorItemsPerLocation=0']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaZoBv5v8Qa9"
      },
      "source": [
        "Set parameters. Do not alter this cell outside of the changing the numeric values.\n",
        "\n",
        "**You might need to change these parameters to get a good result on the harder environments**\n",
        "\n",
        "Please note that increasing `NUM_EPISODES` will result in an increase in time to run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "-DaxveUb8PQv"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def set_parameters():\n",
        "    global NUM_EPISODES, THRESHOLD, GAMMA, EPSILON, TEST_THRESHOLD\n",
        "    NUM_EPISODES = 100\n",
        "    THRESHOLD = 100\n",
        "    GAMMA = 0.75\n",
        "    EPSILON = 1.0\n",
        "    TEST_THRESHOLD = 50\n",
        "\n",
        "    return {\n",
        "      'NUM_EPISODES': NUM_EPISODES,\n",
        "      'THRESHOLD': THRESHOLD,\n",
        "      'GAMMA': GAMMA,\n",
        "      'EPSILON': EPSILON,\n",
        "      'TEST_THRESHOLD': TEST_THRESHOLD\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "T9dAzWLerjKI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'NUM_EPISODES': 100,\n",
              " 'THRESHOLD': 100,\n",
              " 'GAMMA': 0.75,\n",
              " 'EPSILON': 1.0,\n",
              " 'TEST_THRESHOLD': 50}"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzB7i03p8dij"
      },
      "source": [
        "Run all tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xxm2giWM8fcJ",
        "outputId": "99a85a3a-70a3-4a76-dcf7-09cfb5a401e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTING <class 'textworld_express.textworld_express.TextWorldExpressEnv'>, coin, numLocations=5,includeDoors=1,numDistractorItems=0, 0\n",
            "Episode 0, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 1, Reward: 1.0, Actions: ['move south', 'move west', 'move east', 'move north', 'open door to south', 'move west', 'close door to west', 'move east', 'move south', 'close door to north', 'move north', 'close door to north', 'move north', 'move north', 'open door to north', 'move north', 'close door to north', 'move north', 'close door to north', 'close door to south', 'take coin']\n",
            "Episode 2, Reward: 1.0, Actions: ['close door to south', 'take coin']\n",
            "Episode 3, Reward: 1.0, Actions: ['close door to south', 'move north', 'open door to south', 'move south', 'move north', 'close door to north', 'move south', 'take coin', 'move north', 'move south', 'move north', 'close door to north', 'close door to north', 'move south', 'open door to north', 'close door to north', 'move north', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'move north', 'move north', 'close door to north', 'close door to north', 'move north', 'open door to north', 'take coin', 'close door to north', 'take coin', 'move north', 'open door to north', 'take coin', 'open door to north', 'close door to north', 'close door to north', 'move north', 'take coin', 'move north', 'close door to north', 'open door to north', 'open door to north', 'close door to north', 'open door to north', 'move north', 'move south', 'open door to north', 'move north', 'take coin']\n",
            "Episode 4, Reward: 1.0, Actions: ['open door to north', 'open door to north', 'move west', 'open door to west', 'close door to west', 'move east', 'move south', 'open door to north', 'close door to north', 'move west', 'move east', 'take coin']\n",
            "Episode 5, Reward: 1.0, Actions: ['move south', 'open door to north', 'open door to south', 'close door to north', 'open door to north', 'move west', 'close door to west', 'close door to west', 'move east', 'open door to south', 'open door to north', 'open door to south', 'take coin']\n",
            "Episode 6, Reward: 1.0, Actions: ['inventory', 'inventory', 'move west', 'close door to west', 'move west', 'move west', 'move east', 'open door to south', 'open door to south', 'close door to south', 'move south', 'open door to south', 'move north', 'move south', 'move north', 'move west', 'close door to west', 'open door to west', 'close door to west', 'open door to west', 'move west', 'take coin', 'open door to east', 'open door to east', 'move east', 'take coin', 'take coin', 'open door to west', 'open door to west', 'open door to west', 'open door to west', 'move east', 'close door to north', 'move south', 'close door to north', 'open door to north', 'move north', 'close door to north', 'move north', 'move north', 'close door to north', 'move south', 'close door to north', 'open door to north', 'move north', 'open door to north', 'take coin']\n",
            "Episode 7, Reward: 1.0, Actions: ['move west', 'move east', 'close door to north', 'close door to south', 'open door to north', 'move west', 'close door to west', 'take coin', 'move west', 'close door to west', 'take coin', 'move east', 'take coin']\n",
            "Episode 8, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 9, Reward: 1.0, Actions: ['move north', 'open door to north', 'move west', 'take coin', 'open door to west', 'take coin', 'move west', 'move east', 'move west', 'move east', 'open door to west', 'move east', 'open door to north', 'move north', 'open door to south', 'take coin', 'close door to south', 'move south', 'close door to south', 'move south', 'open door to south', 'close door to south', 'close door to south', 'open door to south', 'close door to south', 'open door to south', 'move south', 'take coin']\n",
            "Episode 10, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 11, Reward: 1.0, Actions: ['move west', 'move west', 'close door to west', 'close door to west', 'move west', 'move east', 'move south', 'take coin']\n",
            "Episode 12, Reward: 1.0, Actions: ['move north', 'take coin']\n",
            "Episode 13, Reward: 1.0, Actions: ['close door to north', 'take coin']\n",
            "Episode 14, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 15, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 16, Reward: 1.0, Actions: ['move west', 'move east', 'open door to north', 'open door to north', 'open door to south', 'move west', 'move east', 'close door to south', 'take coin']\n",
            "Episode 17, Reward: 1.0, Actions: ['close door to south', 'move south', 'close door to north', 'take coin']\n",
            "Episode 18, Reward: 1.0, Actions: ['close door to south', 'close door to north', 'take coin']\n",
            "Episode 19, Reward: 1.0, Actions: ['move north', 'move west', 'open door to west', 'move west', 'move east', 'close door to west', 'move east', 'take coin']\n",
            "Episode 20, Reward: 1.0, Actions: ['close door to south', 'open door to north', 'move west', 'close door to west', 'close door to west', 'close door to west', 'close door to west', 'move west', 'take coin', 'move west', 'move west', 'move east', 'open door to south', 'open door to south', 'close door to north', 'take coin']\n",
            "Episode 21, Reward: 1.0, Actions: ['move west', 'take coin', 'move west', 'open door to west', 'move west', 'close door to east', 'close door to east', 'open door to east', 'open door to east', 'open door to east', 'close door to east', 'take coin', 'move east', 'move east', 'close door to east', 'take coin', 'move east', 'move east', 'take coin', 'move east', 'open door to east', 'take coin', 'move east', 'open door to west', 'take coin', 'take coin', 'take coin', 'move west', 'open door to east', 'close door to east', 'close door to east', 'open door to east', 'take coin', 'take coin', 'move east', 'move west', 'take coin', 'move east', 'open door to west', 'move east', 'move west', 'close door to west', 'take coin', 'close door to west', 'take coin', 'open door to west', 'open door to west', 'close door to west', 'close door to west', 'take coin', 'move west', 'open door to west', 'take coin', 'open door to west', 'move west', 'open door to east', 'close door to east', 'move east', 'close door to east', 'take coin', 'open door to east', 'close door to east', 'take coin', 'take coin', 'move east', 'move east', 'open door to east', 'close door to east', 'take coin', 'move east', 'move east', 'take coin', 'take coin', 'take coin', 'move east', 'open door to east', 'open door to east', 'take coin', 'close door to east', 'take coin', 'close door to east', 'take coin', 'take coin', 'open door to east', 'close door to east', 'open door to east', 'take coin', 'take coin', 'take coin', 'open door to east', 'move east', 'close door to west', 'take coin', 'take coin', 'move east', 'take coin']\n",
            "Episode 22, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 23, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 24, Reward: 1.0, Actions: ['close door to north', 'take coin']\n",
            "Episode 25, Reward: 1.0, Actions: ['close door to north', 'open door to south', 'close door to north', 'open door to north', 'take coin']\n",
            "Episode 26, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 27, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 28, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 29, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 30, Reward: 1.0, Actions: ['open door to south', 'take coin']\n",
            "Episode 31, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 32, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 33, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 34, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 35, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 36, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 37, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 38, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 39, Reward: 1.0, Actions: ['open door to north', 'take coin']\n",
            "Episode 40, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 41, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 42, Reward: 1.0, Actions: ['open door to north', 'open door to south', 'take coin']\n",
            "Episode 43, Reward: 1.0, Actions: ['open door to north', 'take coin']\n",
            "Episode 44, Reward: 1.0, Actions: ['move west', 'take coin', 'take coin', 'take coin', 'take coin', 'take coin', 'take coin', 'take coin', 'close door to west', 'take coin', 'move east', 'take coin']\n",
            "Episode 45, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 46, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 47, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 48, Reward: 1.0, Actions: ['move south', 'take coin']\n",
            "Episode 49, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 50, Reward: 1.0, Actions: ['open door to south', 'take coin']\n",
            "Episode 51, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 52, Reward: 1.0, Actions: ['open door to south', 'take coin']\n",
            "Episode 53, Reward: 1.0, Actions: ['move west', 'move east', 'open door to north', 'take coin']\n",
            "Episode 54, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 55, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 56, Reward: 1.0, Actions: ['move north', 'close door to north', 'move west', 'take coin', 'take coin', 'move east', 'move south', 'take coin']\n",
            "Episode 57, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 58, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 59, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 60, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 61, Reward: 1.0, Actions: ['close door to south', 'take coin']\n",
            "Episode 62, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 63, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 64, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 65, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 66, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 67, Reward: 1.0, Actions: ['move north', 'take coin']\n",
            "Episode 68, Reward: 1.0, Actions: ['move south', 'take coin']\n",
            "Episode 69, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 70, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 71, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 72, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 73, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 74, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 75, Reward: 1.0, Actions: ['move south', 'take coin']\n",
            "Episode 76, Reward: 1.0, Actions: ['open door to north', 'take coin']\n",
            "Episode 77, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 78, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 79, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 80, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 81, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 82, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 83, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 84, Reward: 1.0, Actions: ['close door to north', 'take coin']\n",
            "Episode 85, Reward: 1.0, Actions: ['open door to north', 'take coin']\n",
            "Episode 86, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 87, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 88, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 89, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 90, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 91, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 92, Reward: 1.0, Actions: ['open door to south', 'take coin']\n",
            "Episode 93, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 94, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 95, Reward: 1.0, Actions: ['close door to north', 'take coin']\n",
            "Episode 96, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 97, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 98, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 99, Reward: 1.0, Actions: ['take coin']\n",
            "Policy actions: ['take coin']\n",
            "TESTING 1: total_reward 1.0/1 \t (reward: 1.0)\n",
            "TESTING <class 'textworld_express.textworld_express.TextWorldExpressEnv'>, coin, numLocations=5,includeDoors=1,numDistractorItems=0, 1\n",
            "Episode 0, Reward: 1.0, Actions: ['move south', 'close door to west', 'move south', 'close door to south', 'open door to west', 'close door to south', 'close door to south', 'open door to south', 'move west', 'move east', 'close door to south', 'move west', 'take coin']\n",
            "Episode 1, Reward: 1.0, Actions: ['move south', 'close door to south', 'move west', 'move west', 'open door to south', 'close door to south', 'open door to south', 'move west', 'open door to west', 'open door to south', 'move west', 'take coin']\n",
            "Episode 2, Reward: 1.0, Actions: ['close door to south', 'open door to south', 'close door to south', 'move south', 'move south', 'close door to west', 'move west', 'close door to south', 'move west', 'move south', 'open door to south', 'close door to south', 'move south', 'move south', 'close door to south', 'open door to west', 'move west', 'close door to north', 'move east', 'close door to west', 'move west', 'move south', 'open door to south', 'open door to south', 'open door to west', 'move south', 'open door to north', 'close door to north', 'open door to north', 'close door to north', 'open door to north', 'move north', 'move west', 'open door to east', 'take coin']\n",
            "Episode 3, Reward: 1.0, Actions: ['close door to west', 'open door to south', 'open door to south', 'move south', 'close door to north', 'close door to north', 'open door to north', 'close door to north', 'close door to north', 'move north', 'open door to north', 'move north', 'close door to south', 'move south', 'take coin', 'move west', 'open door to south', 'open door to south', 'open door to west', 'open door to south', 'open door to south', 'open door to south', 'move south', 'close door to north', 'open door to north', 'move north', 'move south', 'move north', 'move west', 'open door to east', 'move east', 'open door to south', 'close door to west', 'close door to west', 'move west', 'close door to south', 'move west', 'close door to west', 'open door to south', 'close door to south', 'move south', 'move west', 'close door to west', 'move south', 'open door to west', 'open door to west', 'open door to south', 'close door to west', 'open door to south', 'close door to south', 'move south', 'move south', 'close door to south', 'move south', 'open door to south', 'close door to south', 'open door to west', 'move west', 'close door to east', 'take coin']\n",
            "Episode 4, Reward: 1.0, Actions: ['open door to west', 'open door to west', 'close door to west', 'move south', 'move south', 'move south', 'move west', 'close door to west', 'move west', 'move west', 'open door to south', 'move south', 'close door to north', 'move north', 'move north', 'open door to north', 'open door to north', 'close door to north', 'open door to north', 'move north', 'close door to west', 'close door to west', 'open door to west', 'move west', 'close door to east', 'open door to east', 'take coin']\n",
            "Episode 5, Reward: 1.0, Actions: ['open door to west', 'open door to west', 'close door to west', 'open door to south', 'close door to south', 'close door to west', 'take coin', 'take coin', 'take coin', 'open door to west', 'move west', 'move east', 'close door to west', 'close door to south', 'take coin', 'move south', 'move south', 'open door to west', 'move south', 'close door to west', 'take coin', 'open door to west', 'move south', 'take coin', 'close door to west', 'close door to south', 'open door to south', 'move south', 'move north', 'move south', 'open door to north', 'open door to north', 'close door to north', 'close door to north', 'close door to north', 'move north', 'move north', 'move north', 'take coin', 'close door to north', 'move north', 'move north', 'close door to north', 'open door to north', 'move north', 'close door to south', 'move south', 'open door to south', 'move south', 'close door to north', 'open door to north', 'move north', 'move west', 'open door to south', 'close door to south', 'take coin', 'open door to west', 'take coin', 'take coin', 'close door to south', 'open door to west', 'close door to south', 'move south', 'open door to south', 'take coin', 'open door to west', 'move south', 'open door to north', 'open door to north', 'take coin', 'take coin', 'close door to north', 'move north', 'close door to north', 'close door to north', 'open door to north', 'move north', 'close door to west', 'open door to west', 'move south', 'take coin', 'close door to north', 'open door to north', 'open door to north', 'move north', 'take coin', 'move west', 'close door to north', 'move north', 'take coin']\n",
            "Episode 6, Reward: 1.0, Actions: ['take coin', 'close door to south', 'close door to west', 'close door to south', 'open door to south', 'close door to south', 'close door to west', 'take coin', 'move west', 'move south', 'take coin', 'move west', 'move west', 'open door to south', 'close door to west', 'close door to west', 'close door to south', 'open door to south', 'take coin', 'open door to west', 'take coin', 'take coin', 'take coin', 'move west', 'move north', 'open door to east', 'take coin']\n",
            "Episode 7, Reward: 1.0, Actions: ['move west', 'take coin', 'take coin', 'close door to west', 'move west', 'close door to south', 'close door to west', 'move south', 'open door to west', 'move south', 'take coin', 'close door to south', 'move south', 'close door to south', 'close door to south', 'close door to south', 'move south', 'move south', 'close door to west', 'move west', 'take coin', 'close door to south', 'open door to west', 'move south', 'close door to west', 'move west', 'take coin', 'take coin', 'close door to west', 'close door to south', 'move south', 'open door to west', 'open door to west', 'open door to south', 'close door to south', 'close door to west', 'close door to west', 'move south', 'open door to west', 'close door to south', 'take coin', 'close door to west', 'open door to west', 'close door to south', 'close door to south', 'take coin', 'move west', 'take coin']\n",
            "Episode 8, Reward: 1.0, Actions: ['close door to west', 'close door to south', 'move south', 'move south', 'open door to west', 'move south', 'open door to west', 'move south', 'take coin', 'close door to west', 'open door to west', 'open door to west', 'open door to west', 'open door to south', 'close door to south', 'close door to west', 'open door to west', 'open door to south', 'move west', 'open door to north', 'take coin']\n",
            "Episode 9, Reward: 1.0, Actions: ['close door to south', 'close door to south', 'open door to south', 'open door to west', 'open door to south', 'move south', 'close door to north', 'close door to north', 'move north', 'move north', 'close door to north', 'take coin', 'close door to north', 'open door to north', 'open door to north', 'close door to north', 'move north', 'close door to north', 'move north', 'open door to north', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'open door to north', 'move north', 'open door to south', 'move south', 'move north', 'open door to west', 'open door to west', 'close door to south', 'move west', 'take coin']\n",
            "Episode 10, Reward: 0.0, Actions: ['open door to south', 'open door to south', 'move south', 'take coin', 'take coin', 'open door to north', 'move north', 'close door to south', 'close door to south', 'move south', 'open door to south', 'close door to south', 'close door to west', 'open door to south', 'close door to west', 'open door to south', 'move south', 'open door to north', 'open door to north', 'close door to north', 'close door to north', 'open door to north', 'close door to north', 'open door to north', 'close door to north', 'close door to north', 'open door to north', 'close door to north', 'open door to north', 'move north', 'take coin', 'move west', 'take coin', 'take coin', 'move west', 'move south', 'close door to north', 'take coin', 'close door to north', 'move north', 'close door to north', 'close door to north', 'take coin', 'move north', 'move north', 'take coin', 'open door to north', 'close door to north', 'open door to north', 'take coin', 'move north', 'move south', 'close door to north', 'open door to north', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'inventory', 'move north', 'move north', 'move north', 'close door to north', 'open door to north', 'close door to north', 'close door to south', 'move north', 'move north', 'close door to south', 'open door to south', 'open door to south', 'open door to north', 'move north', 'close door to south', 'move south', 'open door to west', 'open door to south', 'close door to west', 'move west', 'move south', 'move north', 'move south', 'close door to north', 'take coin', 'move north', 'take coin', 'move north', 'move north', 'open door to north', 'take coin', 'close door to north', 'move north', 'move north', 'take coin', 'move north', 'open door to north', 'move north', 'move west', 'open door to south', 'take coin']\n",
            "Episode 11, Reward: 1.0, Actions: ['close door to west', 'close door to west', 'close door to west', 'open door to west', 'take coin', 'open door to south', 'move south', 'open door to north', 'move north', 'open door to west', 'move west', 'open door to east', 'take coin']\n",
            "Episode 12, Reward: 1.0, Actions: ['move west', 'move west', 'move west', 'close door to south', 'move south', 'move west', 'open door to west', 'open door to south', 'close door to west', 'take coin', 'open door to west', 'open door to west', 'close door to west', 'open door to west', 'move south', 'move north', 'open door to west', 'move south', 'open door to north', 'close door to north', 'move north', 'move north', 'move south', 'open door to north', 'open door to north', 'open door to north', 'open door to north', 'take coin', 'open door to north', 'move north', 'open door to west', 'open door to south', 'close door to north', 'close door to west', 'take coin', 'open door to west', 'move south', 'open door to north', 'close door to north', 'close door to north', 'open door to north', 'close door to north', 'close door to north', 'move north', 'move north', 'open door to west', 'move north', 'open door to west', 'open door to north', 'move north', 'move south', 'move north', 'open door to south', 'close door to west', 'open door to west', 'open door to south', 'move west', 'move north', 'move north', 'move north', 'take coin']\n",
            "Episode 13, Reward: 1.0, Actions: ['move south', 'close door to south', 'close door to south', 'move west', 'open door to west', 'close door to south', 'inventory', 'open door to west', 'open door to west', 'move south', 'move west', 'move east', 'close door to south', 'close door to west', 'open door to south', 'move west', 'open door to west', 'inventory', 'move south', 'close door to north', 'inventory', 'move north', 'close door to north', 'open door to north', 'open door to north', 'open door to north', 'close door to north', 'inventory', 'open door to north', 'close door to north', 'close door to north', 'inventory', 'inventory', 'move north', 'open door to north', 'inventory', 'close door to north', 'inventory', 'close door to north', 'close door to north', 'move north', 'move north', 'move north', 'close door to north', 'move north', 'inventory', 'inventory', 'move north', 'open door to north', 'move north', 'close door to west', 'close door to west', 'take coin', 'close door to west', 'move south', 'move north', 'open door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 14, Reward: 1.0, Actions: ['move west', 'close door to south', 'move south', 'move south', 'move south', 'move south', 'open door to west', 'move south', 'open door to west', 'close door to west', 'take coin', 'close door to south', 'move west', 'close door to south', 'move west', 'open door to west', 'move west', 'close door to east', 'take coin']\n",
            "Episode 15, Reward: 1.0, Actions: ['open door to south', 'open door to south', 'close door to west', 'open door to south', 'open door to west', 'open door to south', 'move south', 'open door to north', 'open door to south', 'open door to south', 'open door to north', 'open door to south', 'open door to north', 'close door to north', 'move north', 'close door to north', 'move north', 'move north', 'open door to north', 'inventory', 'close door to north', 'inventory', 'inventory', 'close door to north', 'close door to north', 'inventory', 'move north', 'close door to north', 'move north', 'close door to north', 'move north', 'move north', 'move north', 'inventory', 'close door to north', 'inventory', 'move north', 'open door to north', 'open door to west', 'move north', 'open door to west', 'open door to west', 'open door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 16, Reward: 1.0, Actions: ['close door to south', 'take coin', 'move south', 'close door to west', 'move south', 'move west', 'close door to west', 'open door to south', 'move south', 'close door to north', 'move north', 'close door to north', 'close door to north', 'close door to north', 'open door to north', 'open door to north', 'move west', 'move west', 'close door to north', 'close door to north', 'move north', 'move north', 'open door to north', 'open door to north', 'close door to west', 'open door to north', 'close door to west', 'close door to west', 'close door to north', 'open door to north', 'close door to west', 'close door to west', 'move north', 'take coin', 'close door to west', 'take coin', 'move west', 'take coin', 'move south', 'inventory', 'close door to north', 'close door to north', 'inventory', 'inventory', 'close door to north', 'open door to north', 'move north', 'move west', 'inventory', 'move west', 'open door to south', 'close door to west', 'move south', 'inventory', 'close door to north', 'inventory', 'open door to north', 'move north', 'open door to west', 'inventory', 'open door to south', 'inventory', 'close door to west', 'open door to west', 'inventory', 'move south', 'move north', 'move west', 'move north', 'open door to east', 'take coin']\n",
            "Episode 17, Reward: 1.0, Actions: ['open door to south', 'close door to south', 'take coin', 'open door to south', 'take coin', 'open door to south', 'take coin', 'take coin', 'take coin', 'close door to south', 'take coin', 'open door to south', 'close door to south', 'move west', 'close door to south', 'move south', 'open door to south', 'open door to west', 'open door to west', 'move south', 'open door to north', 'move north', 'open door to south', 'close door to west', 'take coin', 'move west', 'take coin', 'move south', 'move north', 'move south', 'close door to north', 'move north', 'open door to north', 'move north', 'open door to south', 'move south', 'inventory', 'close door to north', 'inventory', 'close door to north', 'open door to north', 'inventory', 'open door to north', 'close door to north', 'move north', 'open door to north', 'close door to north', 'close door to north', 'move north', 'close door to north', 'move north', 'close door to north', 'move north', 'move north', 'open door to north', 'move north', 'close door to south', 'close door to west', 'move west', 'open door to south', 'take coin', 'close door to south', 'take coin', 'take coin', 'move south', 'open door to south', 'open door to south', 'open door to south', 'move south', 'close door to north', 'move north', 'close door to south', 'move north', 'close door to north', 'move north', 'close door to north', 'open door to north', 'close door to north', 'close door to north', 'open door to north', 'open door to north', 'open door to north', 'open door to north', 'open door to north', 'move north', 'open door to west', 'inventory', 'open door to south', 'move west', 'move north', 'close door to east', 'close door to east', 'open door to north', 'move east', 'close door to north', 'take coin']\n",
            "Episode 18, Reward: 1.0, Actions: ['take coin', 'close door to west', 'take coin', 'close door to south', 'close door to south', 'close door to west', 'take coin', 'move west', 'open door to south', 'take coin', 'take coin', 'open door to south', 'move south', 'open door to north', 'open door to north', 'open door to north', 'open door to north', 'open door to north', 'open door to north', 'close door to west', 'close door to north', 'close door to south', 'close door to north', 'close door to south', 'close door to south', 'close door to north', 'close door to north', 'close door to west', 'move north', 'move north', 'open door to north', 'move north', 'take coin', 'move west', 'close door to south', 'close door to south', 'close door to west', 'move south', 'close door to west', 'close door to west', 'inventory', 'close door to west', 'close door to south', 'move south', 'move south', 'open door to west', 'close door to south', 'close door to south', 'move west', 'move north', 'close door to north', 'open door to north', 'take coin']\n",
            "Episode 19, Reward: 1.0, Actions: ['open door to west', 'open door to south', 'close door to south', 'close door to south', 'move south', 'close door to south', 'open door to west', 'close door to south', 'close door to south', 'open door to south', 'close door to south', 'close door to south', 'open door to south', 'close door to south', 'close door to south', 'close door to south', 'open door to west', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'open door to west', 'move south', 'move west', 'open door to north', 'close door to north', 'take coin']\n",
            "Episode 20, Reward: 1.0, Actions: ['move south', 'open door to west', 'open door to south', 'move west', 'move east', 'move west', 'open door to east', 'open door to north', 'take coin']\n",
            "Episode 21, Reward: 1.0, Actions: ['open door to south', 'move south', 'inventory', 'move north', 'open door to west', 'close door to south', 'close door to south', 'move west', 'move east', 'move west', 'take coin']\n",
            "Episode 22, Reward: 1.0, Actions: ['close door to south', 'move west', 'open door to west', 'close door to south', 'close door to south', 'close door to west', 'open door to west', 'close door to south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 23, Reward: 1.0, Actions: ['open door to south', 'take coin', 'move west', 'move south', 'close door to west', 'open door to north', 'close door to west', 'move north', 'move west', 'close door to south', 'close door to south', 'close door to south', 'open door to west', 'inventory', 'open door to west', 'open door to south', 'open door to west', 'move south', 'inventory', 'inventory', 'inventory', 'open door to north', 'close door to north', 'inventory', 'close door to north', 'move north', 'move north', 'move north', 'open door to north', 'move north', 'inventory', 'close door to south', 'close door to south', 'move west', 'take coin']\n",
            "Episode 24, Reward: 1.0, Actions: ['open door to south', 'open door to west', 'close door to south', 'open door to south', 'open door to west', 'close door to south', 'close door to south', 'close door to south', 'move south', 'close door to south', 'close door to south', 'close door to south', 'close door to west', 'move south', 'move west', 'close door to south', 'open door to south', 'move south', 'move north', 'open door to south', 'take coin', 'move west', 'open door to west', 'close door to west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move south', 'move north', 'move west', 'move south', 'close door to north', 'move west', 'open door to north', 'close door to north', 'move west', 'open door to north', 'move west', 'move west', 'open door to north', 'close door to north', 'move west', 'move west', 'move west', 'move west', 'close door to north', 'move west', 'close door to north', 'move west', 'move west', 'close door to north', 'move north', 'move north', 'move west', 'open door to north', 'move west', 'move west', 'move north', 'move west', 'open door to south', 'open door to south', 'open door to east', 'open door to west', 'open door to south', 'close door to south', 'move west', 'open door to east', 'move north', 'take coin']\n",
            "Episode 25, Reward: 1.0, Actions: ['open door to east', 'open door to east', 'open door to east', 'open door to south', 'close door to south', 'move west', 'open door to east', 'open door to east', 'open door to south', 'open door to west', 'open door to east', 'close door to west', 'open door to west', 'open door to west', 'open door to east', 'move south', 'open door to north', 'close door to north', 'move north', 'open door to east', 'open door to east', 'open door to east', 'open door to east', 'close door to east', 'close door to east', 'close door to north', 'close door to east', 'open door to north', 'open door to north', 'close door to east', 'move north', 'close door to west', 'close door to east', 'close door to east', 'move west', 'close door to east', 'move south', 'open door to north', 'close door to east', 'close door to north', 'move north', 'move north', 'close door to east', 'close door to north', 'close door to east', 'move north', 'close door to north', 'open door to north', 'move west', 'move west', 'move west', 'close door to north', 'open door to north', 'move west', 'move north', 'open door to south', 'close door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 26, Reward: 1.0, Actions: ['move south', 'move south', 'open door to south', 'open door to west', 'move west', 'open door to east', 'open door to east', 'close door to east', 'take coin']\n",
            "Episode 27, Reward: 1.0, Actions: ['close door to east', 'move west', 'close door to east', 'open door to south', 'close door to east', 'close door to east', 'open door to west', 'close door to south', 'move west', 'take coin']\n",
            "Episode 28, Reward: 1.0, Actions: ['close door to west', 'close door to south', 'move west', 'open door to west', 'close door to south', 'move south', 'move west', 'take coin']\n",
            "Episode 29, Reward: 1.0, Actions: ['move south', 'open door to south', 'close door to west', 'move south', 'move north', 'move south', 'move west', 'open door to north', 'move north', 'close door to south', 'move south', 'move west', 'close door to west', 'close door to north', 'close door to west', 'open door to west', 'move west', 'close door to north', 'move east', 'move west', 'move north', 'take coin']\n",
            "Episode 30, Reward: 1.0, Actions: ['move west', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'close door to south', 'move south', 'close door to south', 'move south', 'close door to south', 'close door to west', 'open door to south', 'open door to south', 'move south', 'close door to north', 'open door to south', 'open door to south', 'move north', 'open door to south', 'move north', 'open door to south', 'open door to south', 'open door to north', 'open door to south', 'open door to south', 'open door to south', 'open door to south', 'open door to south', 'move north', 'close door to south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 31, Reward: 0.0, Actions: ['open door to west', 'move west', 'open door to north', 'move north', 'move west', 'move west', 'close door to south', 'move north', 'close door to east', 'close door to south', 'open door to north', 'close door to south', 'close door to east', 'close door to east', 'move north', 'open door to south', 'move west', 'move south', 'close door to east', 'close door to east', 'close door to east', 'close door to north', 'close door to north', 'close door to north', 'close door to south', 'close door to south', 'move north', 'close door to north', 'close door to north', 'close door to south', 'open door to south', 'move west', 'move west', 'open door to north', 'move north', 'open door to south', 'move west', 'move south', 'close door to south', 'close door to north', 'move north', 'open door to north', 'move south', 'close door to south', 'open door to south', 'open door to south', 'open door to north', 'move north', 'open door to south', 'open door to south', 'close door to south', 'open door to south', 'move west', 'move west', 'move west', 'move south', 'move north', 'move west', 'close door to south', 'move west', 'move west', 'open door to south', 'move west', 'move west', 'open door to south', 'move west', 'move south', 'move west', 'move west', 'move west', 'close door to north', 'move south', 'move north', 'move west', 'move west', 'move west', 'move west', 'move west', 'close door to north', 'close door to north', 'move west', 'move south', 'move north', 'close door to north', 'open door to north', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move north', 'close door to south', 'open door to south', 'move south', 'move west', 'move west', 'move south', 'close door to north']\n",
            "Episode 32, Reward: 1.0, Actions: ['move south', 'move east', 'move east', 'move east', 'open door to west', 'move west', 'take coin']\n",
            "Episode 33, Reward: 1.0, Actions: ['move east', 'open door to south', 'open door to south', 'move west', 'move east', 'open door to west', 'move west', 'open door to east', 'close door to north', 'move north', 'open door to east', 'take coin']\n",
            "Episode 34, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 35, Reward: 1.0, Actions: ['move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'move east', 'close door to west', 'move east', 'move north', 'move south', 'move west', 'move north', 'move north', 'move north', 'move south', 'move north', 'move west', 'close door to west', 'move north', 'move north', 'move south', 'close door to north', 'close door to north', 'close door to north', 'close door to north', 'open door to south', 'close door to north', 'close door to north', 'open door to west', 'move west', 'take coin']\n",
            "Episode 36, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 37, Reward: 1.0, Actions: ['close door to east', 'close door to east', 'close door to east', 'move south', 'close door to east', 'close door to east', 'move south', 'move west', 'move west', 'move west', 'move west', 'move west', 'move west', 'close door to west', 'move west', 'open door to west', 'open door to south', 'open door to west', 'close door to west', 'move south', 'move north', 'open door to south', 'close door to west', 'open door to south', 'close door to west', 'move west', 'move west', 'close door to south', 'move west', 'move west', 'move west', 'open door to north', 'close door to west', 'open door to north', 'move south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 38, Reward: 1.0, Actions: ['close door to north', 'close door to north', 'open door to west', 'move west', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'close door to north', 'move east', 'move west', 'open door to north', 'take coin']\n",
            "Episode 39, Reward: 1.0, Actions: ['move south', 'move south', 'move south', 'move west', 'move west', 'close door to west', 'move west', 'move south', 'move west', 'move west', 'move west', 'close door to south', 'close door to south', 'take coin', 'open door to west', 'move south', 'close door to west', 'move south', 'take coin', 'open door to west', 'move west', 'move east', 'move west', 'take coin']\n",
            "Episode 40, Reward: 1.0, Actions: ['take coin', 'close door to west', 'move west', 'move north', 'move west', 'move north', 'open door to south', 'move north', 'move north', 'move north', 'open door to west', 'move west', 'take coin']\n",
            "Episode 41, Reward: 1.0, Actions: ['close door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 42, Reward: 1.0, Actions: ['move north', 'close door to west', 'close door to west', 'move north', 'open door to west', 'move west', 'open door to east', 'take coin']\n",
            "Episode 43, Reward: 1.0, Actions: ['move east', 'open door to west', 'close door to south', 'move west', 'open door to east', 'take coin']\n",
            "Episode 44, Reward: 1.0, Actions: ['move east', 'move west', 'open door to south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 45, Reward: 1.0, Actions: ['move south', 'close door to south', 'move south', 'move south', 'move south', 'move south', 'move south', 'close door to west', 'move south', 'move south', 'open door to west', 'move west', 'open door to north', 'open door to east', 'take coin']\n",
            "Episode 46, Reward: 1.0, Actions: ['move south', 'close door to west', 'move west', 'move south', 'open door to west', 'open door to west', 'move west', 'close door to east', 'take coin']\n",
            "Episode 47, Reward: 1.0, Actions: ['move south', 'move south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 48, Reward: 1.0, Actions: ['move south', 'move south', 'close door to west', 'move south', 'move south', 'move south', 'close door to south', 'move south', 'move south', 'move south', 'close door to west', 'close door to west', 'move south', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'open door to west', 'move west', 'take coin']\n",
            "Episode 49, Reward: 1.0, Actions: ['move north', 'move north', 'move north', 'move north', 'close door to south', 'move north', 'move south', 'take coin', 'open door to south', 'take coin', 'take coin', 'take coin', 'close door to west', 'take coin', 'take coin', 'take coin', 'take coin', 'move west', 'move west', 'take coin', 'take coin', 'take coin', 'take coin', 'open door to west', 'move south', 'take coin', 'take coin', 'close door to north', 'move north', 'close door to north', 'open door to north', 'move south', 'open door to north', 'move south', 'move north', 'move west', 'open door to north', 'open door to north', 'close door to east', 'move east', 'move east', 'take coin']\n",
            "Episode 50, Reward: 1.0, Actions: ['move south', 'move west', 'move south', 'move south', 'open door to south', 'move south', 'open door to north', 'move south', 'move north', 'move south', 'open door to north', 'move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'move north', 'move north', 'move north', 'move north', 'close door to west', 'move north', 'close door to west', 'open door to south', 'move north', 'open door to south', 'move north', 'move north', 'move north', 'open door to west', 'move west', 'move north', 'open door to north', 'take coin']\n",
            "Episode 51, Reward: 1.0, Actions: ['move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move south', 'move east', 'move east', 'move east', 'move west', 'move east', 'move east', 'open door to west', 'move west', 'take coin']\n",
            "Episode 52, Reward: 1.0, Actions: ['close door to south', 'move east', 'close door to south', 'move east', 'close door to west', 'move east', 'move south', 'move east', 'open door to south', 'move east', 'move east', 'move east', 'move east', 'move east', 'close door to south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 53, Reward: 1.0, Actions: ['open door to south', 'close door to west', 'move east', 'close door to west', 'move south', 'move south', 'move south', 'move south', 'move south', 'open door to north', 'move south', 'move south', 'move south', 'move south', 'move south', 'open door to north', 'move north', 'open door to west', 'open door to south', 'move west', 'take coin']\n",
            "Episode 54, Reward: 1.0, Actions: ['move south', 'close door to west', 'close door to east', 'close door to east', 'close door to east', 'move west', 'close door to east', 'close door to east', 'close door to east', 'close door to east', 'close door to east', 'close door to east', 'close door to east', 'move south', 'close door to east', 'move west', 'close door to east', 'close door to east', 'close door to east', 'open door to west', 'move west', 'take coin']\n",
            "Episode 55, Reward: 1.0, Actions: ['open door to south', 'close door to west', 'open door to west', 'move west', 'close door to north', 'take coin']\n",
            "Episode 56, Reward: 1.0, Actions: ['move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'move south', 'close door to west', 'move south', 'move south', 'move south', 'close door to south', 'open door to south', 'open door to west', 'open door to west', 'move west', 'close door to north', 'take coin']\n",
            "Episode 57, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 58, Reward: 1.0, Actions: ['open door to south', 'open door to west', 'move west', 'open door to east', 'take coin']\n",
            "Episode 59, Reward: 1.0, Actions: ['inventory', 'close door to south', 'open door to west', 'open door to west', 'move south', 'move west', 'take coin']\n",
            "Episode 60, Reward: 1.0, Actions: ['inventory', 'inventory', 'close door to west', 'close door to south', 'move south', 'move west', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to west', 'move west', 'move north', 'move north', 'open door to south', 'move west', 'open door to south', 'open door to south', 'move south', 'move south', 'open door to north', 'move south', 'move south', 'close door to north', 'move south', 'move south', 'move east', 'move north', 'open door to north', 'close door to north', 'move east', 'move east', 'move north', 'move east', 'open door to north', 'close door to north', 'move east', 'move east', 'open door to north', 'close door to north', 'open door to north', 'move east', 'move north', 'move east', 'move east', 'open door to west', 'move south', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'move north', 'move west', 'close door to north', 'take coin']\n",
            "Episode 61, Reward: 1.0, Actions: ['open door to west', 'open door to south', 'move west', 'take coin']\n",
            "Episode 62, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 63, Reward: 1.0, Actions: ['open door to west', 'close door to west', 'move north', 'move north', 'move north', 'open door to south', 'open door to south', 'open door to south', 'open door to south', 'open door to south', 'open door to south', 'open door to south', 'close door to west', 'open door to south', 'open door to south', 'open door to south', 'move west', 'move south', 'open door to north', 'move west', 'move west', 'move west', 'open door to north', 'open door to north', 'close door to north', 'open door to north', 'move north', 'take coin', 'take coin', 'take coin', 'take coin', 'take coin', 'move west', 'move south', 'move north', 'move south', 'move south', 'move north', 'move south', 'open door to north', 'move south', 'move south', 'move south', 'close door to north', 'move south', 'close door to north', 'move south', 'move south', 'close door to north', 'open door to west', 'move north', 'close door to north', 'open door to west', 'open door to west', 'close door to north', 'open door to north', 'open door to west', 'move north', 'open door to west', 'move west', 'take coin']\n",
            "Episode 64, Reward: 1.0, Actions: ['move east', 'open door to south', 'move east', 'move east', 'open door to south', 'open door to west', 'move west', 'move east', 'move west', 'close door to east', 'take coin']\n",
            "Episode 65, Reward: 1.0, Actions: ['move east', 'move west', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'close door to west', 'move south', 'move east', 'move west', 'move east', 'move south', 'move south', 'open door to south', 'move east', 'close door to west', 'move east', 'move east', 'move east', 'close door to south', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move south', 'move south', 'move south', 'close door to south', 'move south', 'close door to west', 'move south', 'move south', 'move south', 'move west', 'move south', 'open door to south', 'move south', 'move south', 'move north', 'open door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 66, Reward: 1.0, Actions: ['open door to south', 'move west', 'move west', 'move west', 'move west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 67, Reward: 1.0, Actions: ['move south', 'close door to south', 'close door to south', 'open door to west', 'close door to south', 'move west', 'close door to east', 'take coin']\n",
            "Episode 68, Reward: 1.0, Actions: ['move west', 'close door to south', 'close door to south', 'move west', 'close door to south', 'move east', 'move west', 'move east', 'move east', 'move east', 'move east', 'move east', 'move east', 'close door to west', 'close door to west', 'move east', 'move east', 'move north', 'move north', 'move south', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move north', 'move south', 'move south', 'move west', 'move south', 'move south', 'move south', 'move south', 'move south', 'open door to south', 'close door to south', 'open door to south', 'close door to west', 'open door to south', 'open door to south', 'open door to south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 69, Reward: 1.0, Actions: ['close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'open door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'close door to south', 'move west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 70, Reward: 1.0, Actions: ['move south', 'close door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 71, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 72, Reward: 1.0, Actions: ['open door to west', 'move west', 'move east', 'move west', 'take coin']\n",
            "Episode 73, Reward: 1.0, Actions: ['open door to south', 'open door to west', 'close door to south', 'move west', 'open door to east', 'take coin']\n",
            "Episode 74, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 75, Reward: 1.0, Actions: ['close door to south', 'open door to west', 'move west', 'take coin']\n",
            "Episode 76, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 77, Reward: 1.0, Actions: ['close door to west', 'open door to west', 'move west', 'open door to north', 'take coin']\n",
            "Episode 78, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 79, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 80, Reward: 1.0, Actions: ['open door to west', 'move west', 'move north', 'take coin']\n",
            "Episode 81, Reward: 1.0, Actions: ['open door to west', 'close door to west', 'open door to south', 'move west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 82, Reward: 1.0, Actions: ['close door to south', 'open door to west', 'move south', 'move west', 'take coin']\n",
            "Episode 83, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 84, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 85, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 86, Reward: 1.0, Actions: ['open door to west', 'move west', 'close door to north', 'take coin']\n",
            "Episode 87, Reward: 1.0, Actions: ['close door to west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 88, Reward: 1.0, Actions: ['open door to west', 'move west', 'move east', 'move west', 'take coin']\n",
            "Episode 89, Reward: 1.0, Actions: ['move west', 'open door to west', 'move west', 'take coin']\n",
            "Episode 90, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 91, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 92, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 93, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 94, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 95, Reward: 1.0, Actions: ['open door to west', 'move south', 'move west', 'take coin']\n",
            "Episode 96, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 97, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 98, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Episode 99, Reward: 1.0, Actions: ['open door to west', 'move west', 'take coin']\n",
            "Policy actions: ['open door to west', 'move west', 'take coin']\n",
            "TESTING 2: total_reward 2.0/2 \t (reward: 1.0)\n",
            "TESTING <class 'textworld_express.textworld_express.TextWorldExpressEnv'>, coin, numLocations=5,includeDoors=1,numDistractorItems=0, 2\n",
            "Episode 0, Reward: 1.0, Actions: ['close door to north', 'open door to north', 'close door to east', 'take coin']\n",
            "Episode 1, Reward: 1.0, Actions: ['open door to east', 'close door to north', 'open door to north', 'close door to north', 'close door to north', 'open door to east', 'move east', 'move west', 'open door to north', 'move north', 'close door to south', 'open door to south', 'close door to south', 'close door to south', 'open door to south', 'move south', 'take coin']\n",
            "Episode 2, Reward: 1.0, Actions: ['open door to east', 'move north', 'open door to east', 'move north', 'open door to east', 'take coin']\n",
            "Episode 3, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 4, Reward: 1.0, Actions: ['open door to east', 'open door to east', 'move north', 'move east', 'open door to west', 'move west', 'move east', 'open door to west', 'open door to south', 'move south', 'close door to west', 'open door to north', 'move north', 'close door to south', 'close door to west', 'open door to south', 'open door to south', 'move south', 'take coin', 'close door to west', 'move north', 'open door to south', 'close door to south', 'close door to west', 'open door to west', 'open door to west', 'close door to south', 'close door to south', 'open door to west', 'open door to west', 'move west', 'close door to north', 'open door to north', 'close door to north', 'take coin']\n",
            "Episode 5, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 6, Reward: 1.0, Actions: ['open door to north', 'close door to north', 'close door to north', 'take coin']\n",
            "Episode 7, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 8, Reward: 1.0, Actions: ['move east', 'take coin']\n",
            "Episode 9, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 10, Reward: 1.0, Actions: ['move east', 'take coin']\n",
            "Episode 11, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 12, Reward: 1.0, Actions: ['move east', 'close door to north', 'take coin']\n",
            "Episode 13, Reward: 1.0, Actions: ['move east', 'take coin']\n",
            "Episode 14, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 15, Reward: 1.0, Actions: ['open door to east', 'take coin']\n",
            "Episode 16, Reward: 1.0, Actions: ['move north', 'move north', 'move north', 'take coin']\n",
            "Episode 17, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 18, Reward: 1.0, Actions: ['open door to north', 'take coin']\n",
            "Episode 19, Reward: 1.0, Actions: ['move north', 'take coin']\n",
            "Episode 20, Reward: 1.0, Actions: ['open door to north', 'take coin']\n",
            "Episode 21, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 22, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 23, Reward: 1.0, Actions: ['close door to north', 'open door to north', 'open door to east', 'take coin']\n",
            "Episode 24, Reward: 1.0, Actions: ['move east', 'take coin']\n",
            "Episode 25, Reward: 1.0, Actions: ['open door to north', 'open door to east', 'open door to north', 'take coin']\n",
            "Episode 26, Reward: 1.0, Actions: ['close door to east', 'take coin']\n",
            "Episode 27, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 28, Reward: 1.0, Actions: ['move north', 'close door to east', 'open door to north', 'move east', 'close door to north', 'take coin']\n",
            "Episode 29, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 30, Reward: 1.0, Actions: ['open door to east', 'open door to north', 'take coin']\n",
            "Episode 31, Reward: 1.0, Actions: ['move east', 'open door to north', 'close door to east', 'move north', 'move south', 'take coin']\n",
            "Episode 32, Reward: 1.0, Actions: ['take coin']\n",
            "Episode 33, Reward: 1.0, Actions: ['open door to east', 'open door to east', 'take coin']\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[90], line 33\u001b[0m, in \u001b[0;36mrun_all\u001b[1;34m(environments, games, seeds)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Run the DQNAgent and get the policy\u001b[39;00m\n\u001b[0;32m     28\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(action_set,\n\u001b[0;32m     29\u001b[0m                  DQNConfig(),\n\u001b[0;32m     30\u001b[0m                  gamma\u001b[38;5;241m=\u001b[39mGAMMA,\n\u001b[0;32m     31\u001b[0m                  epsilon\u001b[38;5;241m=\u001b[39mEPSILON)\n\u001b[1;32m---> 33\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mENV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESHOLD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# run the policy to get the plan\u001b[39;00m\n\u001b[0;32m     36\u001b[0m plan, reward \u001b[38;5;241m=\u001b[39m run_policy(agent, ENV, threshold \u001b[38;5;241m=\u001b[39m TEST_THRESHOLD)\n",
            "Cell \u001b[1;32mIn[85], line 115\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[1;34m(self, env, num_episodes, threshold)\u001b[0m\n\u001b[0;32m    113\u001b[0m     state_input \u001b[38;5;241m=\u001b[39m state_input\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    114\u001b[0m     Q_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_model(state_input)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 115\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(entry_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQ_output\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    116\u001b[0m   action_set\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact2id[entry_next_action]])\n\u001b[0;32m    118\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "results = run_all(environments, games, seeds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQaep88V13E"
      },
      "source": [
        "# Grading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDcg7IENXtj1"
      },
      "source": [
        "Grading will be done in the same way as Part 1. There will be a total of 63 tests: 1 point for each correct plan per algorithm.\n",
        "\n",
        "**Grading:**\n",
        "\n",
        "Maximum total points: 50\n",
        "\n",
        "| # correct plan | Score |\n",
        "|----------|-------|\n",
        "| >= 50   |  50   |\n",
        "| 49      |  49   |\n",
        "| 48      |  48   |\n",
        "| ...      |  ...  |\n",
        "| 2      |  2   |\n",
        "| 1       |   1  |\n",
        "| 0   |   0   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA0XSuitsCP5"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Upload this notebook with the name `hw2_part2.ipynb` file to Gradescope. Part 2 will be graded on our local GPU machines. Final grades will be uploaded on Gradescope after the submission deadline.\n",
        "\n",
        "We've added appropriate comments to the top of certain cells for the autograder to export (`# export`). You do NOT have to do anything (e.g. remove print statements) to cells we have provided - anything related to those have been handled for you. You are responsible for ensuring your own code has no syntax errors or unnecessary print statements. You ***CANNOT*** modify the export comments at the top of the cells, or the autograder will fail to run on your submission.\n",
        "\n",
        "You should ***not*** add any cells to the notebook when submitting. You're welcome to add any code as you need to extra cells when testing, but you must remove them when submitting.\n",
        "\n",
        "If you identify an issue with the autograder, please feel free to reach out to us on Piazza, or email bok004@ucsd.edu."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NMJadvTO-O7z",
        "f0GaE8xE-T6A",
        "2sGpjl4N4YP9",
        "UhgPPbfb9ANG"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mangrove-monitoring",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01d2bdd36f814e3fb134a3e9448c85ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9176817e2ea84b62979d94147e480530",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef3c33a2a74246999f326a8331208ec8",
            "value": 26
          }
        },
        "0901f8bc04c747a0841b5108f0a01da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e06cc9e741f4d3a817ac368d30b19ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb6a7c0ba214a8ea69091c6b561c5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "100bb8dbe1a441e9adf1e81013b7ed5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125b82cd74184e2f9399afafd391c511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1280b721212e463398dad9a9269ec2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bca33ada594a618759ee84c1ff3494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100bb8dbe1a441e9adf1e81013b7ed5c",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d23744705b6c4a4986ae9a0051ffa767",
            "value": 1042301
          }
        },
        "28813c105e7946b9b4fe9ae500b39023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20276010dd343df9a5498795131f57e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_125b82cd74184e2f9399afafd391c511",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡14.2MB/s]"
          }
        },
        "29a68ad51db7437cb1e708f82597ba4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a72ce34d14e49e9942b611381134e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47c8e12c443c4a6a947b4b7e8bccb8a6",
              "IPY_MODEL_8d73812e12354b6fb8d9b9ad928c8d86",
              "IPY_MODEL_28813c105e7946b9b4fe9ae500b39023"
            ],
            "layout": "IPY_MODEL_a95d2510d9ad4df683fbfb22e5b4dde0"
          }
        },
        "3acbd604c6b3487eae42ffb73da068e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4cd11d435f47c09ee3b560fc53044f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a76986c2114f0285f1d113cfaef9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e81bb07cf64455a91aaebb9b592cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c8e12c443c4a6a947b4b7e8bccb8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c710352c2740abb073ced77e824987",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_99bf57b7e6714f9ba8ac3e67b0852a22",
            "value": "merges.txt:â€‡100%"
          }
        },
        "490f64b6f88540c69b52187946a6fc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5f68ab463643a085166a75405b5d44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e00825f6e34fbba86863fd162bf93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb90a41322e4018a19e00cc2e97f236",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c364fb971bb148b89489b1dd4858e6a9",
            "value": 665
          }
        },
        "6cb62602bbff41c9a0a9a0e2ac7fde3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c03d55ad6e42b2ad28bd4e94d6c864": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf879b0dcb684ba68cf666aee89c9ccb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0eb6a7c0ba214a8ea69091c6b561c5f2",
            "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡2.39MB/s]"
          }
        },
        "7798dbd0a7404904a11b0199ce3b8ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd0c526ec5548ef94c53abdedd8fa95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a9983fac2884ddb9507bfa3065cf12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e06cc9e741f4d3a817ac368d30b19ff",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f943b84dce384188ac572eab0a24967f",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡801B/s]"
          }
        },
        "8c6ff33b38d94cb48a79d37671741eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4cd11d435f47c09ee3b560fc53044f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6cb62602bbff41c9a0a9a0e2ac7fde3d",
            "value": "config.json:â€‡100%"
          }
        },
        "8d73812e12354b6fb8d9b9ad928c8d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1280b721212e463398dad9a9269ec2e4",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6837c8777f244b8a5a48aa23960d0ed",
            "value": 456318
          }
        },
        "9176817e2ea84b62979d94147e480530": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9967e32e6143496f8893e4a8941a2043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3acbd604c6b3487eae42ffb73da068e9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_490f64b6f88540c69b52187946a6fc93",
            "value": "â€‡665/665â€‡[00:00&lt;00:00,â€‡15.2kB/s]"
          }
        },
        "99bf57b7e6714f9ba8ac3e67b0852a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b050daab9124a86be8855f82b651a31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c710352c2740abb073ced77e824987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95d2510d9ad4df683fbfb22e5b4dde0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb90a41322e4018a19e00cc2e97f236": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade0f6ba1195472fb29f9d4141832cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2274c8560d340a1ae38e85f25817c90",
              "IPY_MODEL_01d2bdd36f814e3fb134a3e9448c85ad",
              "IPY_MODEL_8a9983fac2884ddb9507bfa3065cf12c"
            ],
            "layout": "IPY_MODEL_dd4fbf4066374253ad16143f96a1b1f6"
          }
        },
        "b01ce2a8b721466590e8aff1a3bfd10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe936253ad4c4b049fe050ae6f7e62ef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0901f8bc04c747a0841b5108f0a01da0",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡3.14MB/s]"
          }
        },
        "b6837c8777f244b8a5a48aa23960d0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba9e8fc74a8f46ce87b1512c1e7c1546": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b050daab9124a86be8855f82b651a31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7798dbd0a7404904a11b0199ce3b8ed0",
            "value": "vocab.json:â€‡100%"
          }
        },
        "bf879b0dcb684ba68cf666aee89c9ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe3ae9de1674d0baa92919aa8ff476c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e81bb07cf64455a91aaebb9b592cb8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f14b30395edd4bf0802d9c9a6fb7baad",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "c1e26d30e6fe4b3f8eacce4b2e499363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c6ff33b38d94cb48a79d37671741eca",
              "IPY_MODEL_63e00825f6e34fbba86863fd162bf93a",
              "IPY_MODEL_9967e32e6143496f8893e4a8941a2043"
            ],
            "layout": "IPY_MODEL_d9da8f9cd4ba4eab91778d86a309baa6"
          }
        },
        "c364fb971bb148b89489b1dd4858e6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d20276010dd343df9a5498795131f57e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d23744705b6c4a4986ae9a0051ffa767": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5ba1c8986ff4ef593201abe949df2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba9e8fc74a8f46ce87b1512c1e7c1546",
              "IPY_MODEL_14bca33ada594a618759ee84c1ff3494",
              "IPY_MODEL_70c03d55ad6e42b2ad28bd4e94d6c864"
            ],
            "layout": "IPY_MODEL_42a76986c2114f0285f1d113cfaef9e8"
          }
        },
        "d9da8f9cd4ba4eab91778d86a309baa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4fbf4066374253ad16143f96a1b1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d5a481148b40e59c1aeb859e6bf5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eba7a4d7aa8e425b9cbe8e31c459483e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfe3ae9de1674d0baa92919aa8ff476c",
              "IPY_MODEL_fc4f9c38b9a1488c9aa2d17829723785",
              "IPY_MODEL_b01ce2a8b721466590e8aff1a3bfd10d"
            ],
            "layout": "IPY_MODEL_4a5f68ab463643a085166a75405b5d44"
          }
        },
        "ef3c33a2a74246999f326a8331208ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14b30395edd4bf0802d9c9a6fb7baad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2274c8560d340a1ae38e85f25817c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd0c526ec5548ef94c53abdedd8fa95",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f78d1ce3a6da4c71a515616f4e448b6a",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "f78d1ce3a6da4c71a515616f4e448b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f943b84dce384188ac572eab0a24967f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4f9c38b9a1488c9aa2d17829723785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a68ad51db7437cb1e708f82597ba4b",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d5a481148b40e59c1aeb859e6bf5ce",
            "value": 1355256
          }
        },
        "fe936253ad4c4b049fe050ae6f7e62ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
